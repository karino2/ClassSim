{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train multi-class classifier.\n",
    "\n",
    "We train a multi-class classifier to compare the results of $ClassSim$ computed using the multi-class classifier with those of OVR case.  \n",
    "We only require one classifier as we stated in our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH=\"trained_model\"\n",
    "%mkdir -p $BASE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH=\"{}/multiclass\".format(BASE_MODEL_PATH)\n",
    "%mkdir -p $SAVE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.modelutils import dir2filedict, split_fdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load category and file path information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdict = dir2filedict(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted(fdict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data int {train, validation, test} datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict, testdict = split_fdict(fdict, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict, valdict = split_fdict(trdict, test_size=0.2, random_state = 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/clouds/0678.jpeg',\n",
       " 'data/clouds/0701.jpeg',\n",
       " 'data/clouds/0431.jpeg',\n",
       " 'data/clouds/0033.jpeg',\n",
       " 'data/clouds/0290.jpeg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdict['clouds'][0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Here is expected output. The result might be different due to files excluded for GMM, but all the output of\n",
    "# train.ipynb, classifier_similarity.ipynb, train_second.ipynb must be the same.\n",
    "# The output may be different if you create image urls yourself.\n",
    "\n",
    "['data/clouds/0678.jpeg',\n",
    " 'data/clouds/0701.jpeg',\n",
    " 'data/clouds/0431.jpeg',\n",
    " 'data/clouds/0033.jpeg',\n",
    " 'data/clouds/0290.jpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy images files into temporary directories\n",
    "\n",
    "In order to handle datasets as a suitable format of Keras ImageDataGenerator, images are copied into temporary directories with a specific structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_dir = tempfile.TemporaryDirectory()\n",
    "tmp_valid_dir = tempfile.TemporaryDirectory()\n",
    "tmp_test_dir = tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(tmp_dir, data_dict):\n",
    "    for cat in data_dict.keys():\n",
    "        os.makedirs(\"{}/{}\".format(tmp_dir.name, cat), exist_ok=True)\n",
    "        for img_path in data_dict[cat]:\n",
    "            img_name = img_path.split(\"/\")[-1]\n",
    "            shutil.copy2(img_path, \"{}/{}/{}\".format(tmp_dir.name, cat, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 5.41 s, total: 6.5 s\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_images(tmp_train_dir, trdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 264 ms, sys: 1.29 s, total: 1.56 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_images(tmp_valid_dir, valdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 344 ms, sys: 1.58 s, total: 1.92 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_images(tmp_test_dir, testdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7489 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(\n",
    "        directory=tmp_train_dir.name,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1880 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "VALID_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "VALID_GENERATOR = VALID_DATAGEN.flow_from_directory(\n",
    "        directory=tmp_valid_dir.name,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2352 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(\n",
    "        directory=tmp_test_dir.name,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multi-class classifier and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(TRAIN_GENERATOR.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:len(base_model.layers)]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[len(base_model.layers):]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001, decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "234/234 [==============================] - 534s 2s/step - loss: 1.1624 - acc: 0.6197 - val_loss: 0.7798 - val_acc: 0.7268\n",
      "Epoch 2/5\n",
      "234/234 [==============================] - 523s 2s/step - loss: 0.8010 - acc: 0.7242 - val_loss: 0.7780 - val_acc: 0.7220\n",
      "Epoch 3/5\n",
      "234/234 [==============================] - 514s 2s/step - loss: 0.7183 - acc: 0.7501 - val_loss: 0.7599 - val_acc: 0.7306\n",
      "Epoch 4/5\n",
      "234/234 [==============================] - 529s 2s/step - loss: 0.6750 - acc: 0.7708 - val_loss: 0.7622 - val_acc: 0.7252\n",
      "Epoch 5/5\n",
      "234/234 [==============================] - 524s 2s/step - loss: 0.6461 - acc: 0.7763 - val_loss: 0.7592 - val_acc: 0.7306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9138c46080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    generator=TRAIN_GENERATOR\n",
    "    , steps_per_epoch=TRAIN_GENERATOR.n // BATCH_SIZE \n",
    "    , epochs=5\n",
    "    , verbose=1\n",
    "    , validation_data=VALID_GENERATOR\n",
    "    , validation_steps=VALID_GENERATOR.n // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('{}/multiclass.h5'.format(SAVE_MODEL_PATH))\n",
    "with open(\"{}/multiclass.json\".format(SAVE_MODEL_PATH), 'w') as f:\n",
    "    json.dump(json.loads(model.to_json()), f) # model.to_json() is a STRING of json\n",
    "with open(\"{}/multiclass-labels.json\".format(SAVE_MODEL_PATH), 'w') as f:\n",
    "    json.dump(TRAIN_GENERATOR.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate trained model under experiment of simple classification\n",
    "\n",
    "Evaluation of the trained classifier with 16 classes multi-class classification using test datasets.  \n",
    "This evaluation is not related to our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 51s, sys: 17.3 s, total: 6min 8s\n",
      "Wall time: 2min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.73933519242161094, 0.73979591836734693]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.evaluate_generator(\n",
    "    TEST_GENERATOR\n",
    "    , steps=TEST_GENERATOR.n\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left: loss, right: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
