{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train multi-class classifier.\n",
    "\n",
    "We train another set of classifiers that are used for classifications.  \n",
    "These classifiers are trained using similar images for each target class; similarities between classes are computed in *classifier_similarity.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH=\"trained_model\"\n",
    "%mkdir -p $BASE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH=\"{}/multiclass\".format(BASE_MODEL_PATH)\n",
    "%mkdir -p $SAVE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import dir2filedict, split_fdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load category and file path information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdict = dir2filedict(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted(fdict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data int {train, validation, test} datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict, testdict = split_fdict(fdict, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict, valdict = split_fdict(trdict, test_size=0.2, random_state = 456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdict['clouds'][0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Here is expected output. The result might be different due to files excluded for GMM, but all the output of\n",
    "# train.ipynb, classifier_similarity.ipynb, train_second.ipynb must be the same.\n",
    "# The output may be different if you create image urls yourself.\n",
    "\n",
    "['data/clouds/0678.jpeg',\n",
    " 'data/clouds/0701.jpeg',\n",
    " 'data/clouds/0431.jpeg',\n",
    " 'data/clouds/0033.jpeg',\n",
    " 'data/clouds/0290.jpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy images files into temporary directories\n",
    "\n",
    "In order to handle datasets as a suitable format of Keras ImageDataGenerator, images are copied into temporary directories with a specific structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_dir = tempfile.TemporaryDirectory()\n",
    "tmp_valid_dir = tempfile.TemporaryDirectory()\n",
    "tmp_test_dir = tempfile.TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(tmp_dir, data_dict):\n",
    "    for cat in data_dict.keys():\n",
    "        os.makedirs(\"{}/{}\".format(tmp_dir.name, cat), exist_ok=True)\n",
    "        for img_path in data_dict[cat]:\n",
    "            img_name = img_path.split(\"/\")[-1]\n",
    "            shutil.copy2(img_path, \"{}/{}/{}\".format(tmp_dir.name, cat, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "copy_images(tmp_train_dir, trdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "copy_images(tmp_valid_dir, valdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "copy_images(tmp_test_dir, testdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(\n",
    "        directory=tmp_train_dir.name,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "VALID_GENERATOR = VALID_DATAGEN.flow_from_directory(\n",
    "        directory=tmp_valid_dir.name,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATAGEN = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(\n",
    "        directory=tmp_test_dir.name,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multi-class classifier and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(TRAIN_GENERATOR.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:len(base_model.layers)]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[len(base_model.layers):]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001, decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator=TRAIN_GENERATOR\n",
    "    , steps_per_epoch=TRAIN_GENERATOR.n // BATCH_SIZE \n",
    "    , epochs=5\n",
    "    , verbose=1\n",
    "    , validation_data=VALID_GENERATOR\n",
    "    , validation_steps=VALID_GENERATOR.n // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('{}/multiclass.h5'.format(SAVE_MODEL_PATH))\n",
    "with open(\"{}/multiclass.json\".format(SAVE_MODEL_PATH), 'w') as f:\n",
    "    json.dump(json.loads(model.to_json()), f) # model.to_json() is a STRING of json\n",
    "with open(\"{}/multiclass-labels.json\".format(SAVE_MODEL_PATH), 'w') as f:\n",
    "    json.dump(TRAIN_GENERATOR.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate trained model under experiment of simple classification\n",
    "\n",
    "Evaluation of the trained classifier with 16 classes multi-class classification using test datasets.  \n",
    "This evaluation is not related to our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.evaluate_generator(\n",
    "    TEST_GENERATOR\n",
    "    , steps=TEST_GENERATOR.n\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left: loss, right: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
