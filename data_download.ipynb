{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [\n",
    "    \"bay\",\n",
    "    \"beach\",\n",
    "    \"birds\",\n",
    "    \"boeing\",\n",
    "    \"buildings\",\n",
    "    \"city\",\n",
    "    \"clouds\",\n",
    "    \"face\",\n",
    "    \"f-16\",\n",
    "    \"helicopter\",\n",
    "    \"mountain\",\n",
    "    \"sky\",\n",
    "    \"ships\",\n",
    "    \"sunset\",\n",
    "    \"sunrise\",\n",
    "    \"ocean\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_urls(cat):\n",
    "    with open(\"urls/{}.txt\".format(cat), encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.rsplit('\\n')[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import urllib.request\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = {\"jpeg\", \"png\", \"gif\"}\n",
    "\n",
    "def get_one(dirname, urlidx, urls):\n",
    "    url = urls[urlidx]\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        ext = response.info().get_content_subtype()\n",
    "        if not ext in accepted:\n",
    "            return False\n",
    "    urllib.request.urlretrieve(url, \"{}/{:04d}.{}\".format(dirname, urlidx, ext))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORKERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_many_no_error_handle(urls, dirname):\n",
    "    with futures.ThreadPoolExecutor(MAX_WORKERS) as executor:\n",
    "        res = executor.map(lambda idx: get_one(dirname, idx, urls), range(len(urls)))\n",
    "    _ = len(list(res))\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from  http.client import RemoteDisconnected\n",
    "from http.client import HTTPException\n",
    "import ssl\n",
    "\n",
    "def download_many(urls, dirname):\n",
    "    to_do_map = {}\n",
    "    fails = []\n",
    "    with futures.ThreadPoolExecutor(MAX_WORKERS) as executor:\n",
    "        for i in range(len(urls)):\n",
    "            future = executor.submit(get_one,\n",
    "                            dirname, i, urls)\n",
    "            to_do_map[future] = i\n",
    "        done_iter = futures.as_completed(to_do_map)\n",
    "        \n",
    "        done_iter = tqdm.tqdm(done_iter, total=len(urls))\n",
    "        \n",
    "        notify_err = lambda msg: None\n",
    "        \n",
    "        #notify_err = print\n",
    "\n",
    "        \n",
    "        for future in done_iter:\n",
    "            idx = to_do_map[future]\n",
    "            try:\n",
    "                res = future.result()\n",
    "                # print(\"deb\")\n",
    "                if not res:\n",
    "                    notify_err(\"Unknown mime type: {}\".format(urls[idx]))\n",
    "                    fails.append(urls[idx])\n",
    "            # make exception handling separately for debug purpose (now we can merge, but not yet)\n",
    "            except (urllib.error.HTTPError, RemoteDisconnected, ssl.CertificateErr or, OSError, UnicodeEncodeError, urllib.error.URLError):\n",
    "                notify_err(\"urllib retrieve rrorr: {}\".format(urls[idx]))\n",
    "                fails.append(urls[idx])\n",
    "            except HTTPException:\n",
    "                notify_err(\"HTTPException rrorr: {}\".format(urls[idx]))\n",
    "                fails.append(urls[idx])\n",
    "                \n",
    "    return fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_one_category(cat):\n",
    "    urls = read_urls(cat)\n",
    "    dirname = \"data/{}\".format(cat)\n",
    "    \n",
    "    !mkdir -p $dirname\n",
    "    fail_urls = download_many(urls, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984/984 [03:06<00:00,  5.27it/s]\n",
      "100%|██████████| 1000/1000 [03:01<00:00,  5.49it/s]\n",
      "100%|██████████| 989/989 [06:41<00:00,  2.46it/s]\n",
      "100%|██████████| 718/718 [02:32<00:00,  4.70it/s]\n",
      "100%|██████████| 868/868 [02:33<00:00,  5.66it/s]\n",
      "100%|██████████| 864/864 [01:25<00:00, 10.09it/s]\n",
      "100%|██████████| 805/805 [01:11<00:00, 11.33it/s]\n",
      "100%|██████████| 984/984 [02:27<00:00,  6.68it/s]\n",
      "100%|██████████| 693/693 [00:51<00:00, 13.41it/s]\n",
      "100%|██████████| 835/835 [00:50<00:00, 16.47it/s]\n",
      "100%|██████████| 985/985 [01:29<00:00, 10.96it/s]\n",
      "100%|██████████| 873/873 [02:42<00:00,  5.37it/s]\n",
      "100%|██████████| 842/842 [13:04<00:00,  1.07it/s]\n",
      "100%|██████████| 920/920 [01:20<00:00, 11.44it/s]\n",
      "100%|██████████| 727/727 [00:47<00:00, 15.17it/s]\n",
      "100%|██████████| 912/912 [02:20<00:00,  6.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(download_one_category, concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 864/864 [01:13<00:00, 11.83it/s]\n",
      "100%|██████████| 805/805 [02:06<00:00,  6.38it/s]\n",
      "100%|██████████| 984/984 [02:30<00:00,  6.56it/s]\n",
      "100%|██████████| 693/693 [01:02<00:00, 11.06it/s]\n",
      "100%|██████████| 835/835 [00:57<00:00, 14.57it/s]\n",
      "100%|█████████▉| 983/985 [01:39<00:00,  9.93it/s]"
     ]
    }
   ],
   "source": [
    "list(map(download_one_category, concepts[5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_one_category(\"birds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:36<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "download_one_category(\"beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"birds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = read_urls(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"data/{}\".format(cat)\n",
    "\n",
    "!mkdir -p $dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984/984 [03:13<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Need to trust this book\n",
    "\n",
    "fail_urls = download_many(urls, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [urls.index(f) for f in fail_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
