{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train second set of one vs. rest (OVR) classifiers.\n",
    "\n",
    "We train another set of classifiers that are used for classifications.  \n",
    "These classifiers are trained using similar images for each target class; similarities between classes are computed in *classifier_similarity.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH=\"trained_model\"\n",
    "%mkdir -p $BASE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.modelutils import ModelCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler = ModelCompiler(BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.processor import create_generators\n",
    "\n",
    "TRAIN_DATAGEN, VALID_DATAGEN = create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import dir2filedict_sorted\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load category and file path information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict = dir2filedict_sorted(\"data_fgvc/train\")\n",
    "valdict = dir2filedict_sorted(\"data_fgvc/valid\")\n",
    "categories = [str(i) for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdict['0'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is expected outputs.   \n",
    "All the outputs in {*train.ipynb*, *classifier_similarity.ipynb*, *train_multiclass_classifier.ipynb*, *train_second.ipynb*} must be the same. \n",
    "\n",
    "['data_fgvc/valid/0/0062781.jpg',  \n",
    " 'data_fgvc/valid/0/0113201.jpg',  \n",
    " 'data_fgvc/valid/0/0450014.jpg',  \n",
    " 'data_fgvc/valid/0/0602177.jpg',  \n",
    " 'data_fgvc/valid/0/0716386.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train second level classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class for training second level classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.one_vs_all import OneVsAllModelTrainer\n",
    "from models.modelutils import split_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OneVsAllModelTrainer(TRAIN_DATAGEN, VALID_DATAGEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.one_vs_all import FilesPair, TrValFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondLevelClassifierTrainer:\n",
    "    def __init__(self, base_model_name, basedir, trainer, compiler):\n",
    "        self.base_model_name = base_model_name\n",
    "        self.basedir = basedir\n",
    "\n",
    "        self.compiler = compiler\n",
    "        self.trainer = trainer\n",
    "        \n",
    "    def setup_filedict(self, train_files_dict, valid_files_dict):\n",
    "        self.train_files_dict = train_files_dict\n",
    "        self.valid_files_dict = valid_files_dict\n",
    "        self.valid_files_dict_org = self.valid_files_dict\n",
    "        \n",
    "    def _model_path(self, target_key):\n",
    "        return os.path.join(self.basedir, \"{}_{}\".format(self.base_model_name, target_key))\n",
    "    \n",
    "    def _split_by_set(self, target_key, false_keyset, files_dict):\n",
    "        trues = files_dict[target_key]\n",
    "        falses = [path for key in false_keyset for path in files_dict[key]]\n",
    "        return FilesPair(trues, falses)\n",
    "    \n",
    "    def _split_files(self, targetkey, files_dict):\n",
    "        return FilesPair(*split_files(targetkey, files_dict))\n",
    "    \n",
    "    def train_second_level(self, target_key, highcat_keyset, eachepochs=10, retrainings=1, removecheckpoint=True):\n",
    "        self.trainer.retrainings = retrainings\n",
    "        falseset = highcat_keyset - set(target_key)\n",
    "        trs = self._split_by_set(target_key, falseset, self.train_files_dict)\n",
    "        vals = self._split_by_set(target_key, falseset, self.valid_files_dict)\n",
    "        trvals = TrValFiles(trs, vals)\n",
    "        self._train_one_core(\"sec_\"+target_key, trvals, eachepochs, removecheckpoint)\n",
    "        \n",
    "    def _train_one_setup(self, model_key, trvals):\n",
    "        model_save_path = self._model_path(model_key)\n",
    "\n",
    "        model = self.compiler.generate_compiled_model(model_save_path)\n",
    "        self.trainer.set_model(model)\n",
    "        self.trainer.set_savepath(model_save_path)\n",
    "        self.trainer.set_dataset(trvals)\n",
    "\n",
    "    def _train_one_core(self, model_key, trvals, eachepochs, removecheckpoint):\n",
    "        self._train_one_setup(model_key, trvals)\n",
    "\n",
    "        self.trainer.train_model(eachepochs=eachepochs, hard_coded_steps_per_epoch=(100, 10))\n",
    "        if removecheckpoint:\n",
    "            self.trainer.remove_checkpoint()\n",
    "\n",
    "    def remove_checkpoint(self, model_key):\n",
    "        # utility method for cleaup interrupted case\n",
    "        self.trainer.set_savepath(self._model_path(model_key))\n",
    "        self.trainer.remove_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_trainer = SecondLevelClassifierTrainer(\"modelfgvc\", BASE_MODEL_PATH, trainer, compiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_trainer.setup_filedict(trdict, valdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $ClassSim$ results to gather similar classes for each target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classsim = pd.read_pickle(\"results/valid_sim_df_fgvc.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIM_THRESHOLD = 0.1\n",
    "# This data set is much fine grained. So threshold should be higher. We choose 0.4 for average similary class as about 18.\n",
    "SIM_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def list_checkpoints_except_last(model_abs_path_prefix):\n",
    "    pat = \"{}-*.h5\".format(model_abs_path_prefix)\n",
    "    paths = list(glob.iglob(pat))\n",
    "    laststarts = \"{}-99\".format(model_abs_path_prefix)\n",
    "    return [path for path in paths if not path.startswith(laststarts)]\n",
    "\n",
    "def remove_except_last(model_abs_path_prefix):\n",
    "    list(map(os.remove, list_checkpoints_except_last(model_abs_path_prefix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removetype= [\"keeplast\" ,\"keepbest\", None]\n",
    "\n",
    "def train_seconds(keys, eachepochs=5, removecheckpoint=\"keeplast\"):\n",
    "    keepbest = removecheckpoint==\"keepbest\"\n",
    "    keeplast = removecheckpoint==\"keeplast\"\n",
    "    print(keepbest, keeplast)\n",
    "    for targetkey in keys:\n",
    "        similarkeyset = set(classsim[targetkey][classsim[targetkey] >= SIM_THRESHOLD].index)\n",
    "        try:\n",
    "            if len(similarkeyset) == 1:\n",
    "                print(\"no similar category. only first classifier is enough. skip second training.\")\n",
    "            else:\n",
    "                sec_trainer.train_second_level(targetkey, similarkeyset, eachepochs=eachepochs, removecheckpoint=keepbest)\n",
    "                if keeplast:\n",
    "                    print(\"deb here\")\n",
    "                    remove_except_last(sec_trainer._model_path(\"sec_\" + targetkey))\n",
    "        except ValueError as e:\n",
    "            print(\"ValueError, skip {0}: {1}\".format(targetkey, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_seconds(categories[0:], eachepochs=2, removecheckpoint=\"keepbest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether model is property learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cat = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarkeyset = set(classsim[target_cat][classsim[target_cat] >= SIM_THRESHOLD].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarkeyset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '13', '15', '22', '45']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falseset = list(sorted(similarkeyset - set(target_cat)))\n",
    "falseset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import load_best_model_if_exist\n",
    "import os\n",
    "from models.processor import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = load_best_model_if_exist(\"trained_model/modelfgvc_sec_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = valdict['0']+valdict[falseset[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ds.files_to_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_0.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12177239,  0.14247935,  0.13586961,  0.10310103,  0.11975336,\n",
       "        0.29116184,  0.25873953,  0.07083958,  0.05815217,  0.05779626,\n",
       "        0.06138925,  0.05145602,  0.09198892,  0.19282584], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg',\n",
       " 'data_fgvc/valid/0/0869722.jpg',\n",
       " 'data_fgvc/valid/0/1514481.jpg',\n",
       " 'data_fgvc/valid/52/0062226.jpg',\n",
       " 'data_fgvc/valid/52/0136197.jpg',\n",
       " 'data_fgvc/valid/52/0171956.jpg',\n",
       " 'data_fgvc/valid/52/0523171.jpg',\n",
       " 'data_fgvc/valid/52/0523172.jpg',\n",
       " 'data_fgvc/valid/52/0894317.jpg',\n",
       " 'data_fgvc/valid/52/1627560.jpg']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9577Epoch 00001: saving model to trained_model/modelfgvc_sec_0-01-0.845.h5\n",
      "100/100 [==============================] - 151s 2s/step - loss: 0.0962 - acc: 0.9581 - val_loss: 0.4193 - val_acc: 0.8446\n",
      "Epoch 2/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9823Epoch 00002: saving model to trained_model/modelfgvc_sec_0-02-0.804.h5\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.0432 - acc: 0.9813 - val_loss: 0.5769 - val_acc: 0.8041\n",
      "Epoch 3/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9722Epoch 00003: saving model to trained_model/modelfgvc_sec_0-03-0.818.h5\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.0686 - acc: 0.9719 - val_loss: 0.6334 - val_acc: 0.8176\n"
     ]
    }
   ],
   "source": [
    "train_seconds(list(categories[0]), eachepochs=3, removecheckpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import load_model_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 2\n",
    "model_0 = load_model_from(\"trained_model/modelfgvc_sec_0.json\", \"trained_model/modelfgvc_sec_0-02-0.872.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_0.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39031339,  0.00246694,  0.24623962,  0.99023902,  0.00664667,\n",
       "        0.08404001,  0.87686318,  0.17210899,  0.02940854,  0.0094766 ,\n",
       "        0.98935497,  0.92093688,  0.81629044,  0.82622737], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg',\n",
       " 'data_fgvc/valid/0/0869722.jpg',\n",
       " 'data_fgvc/valid/0/1514481.jpg',\n",
       " 'data_fgvc/valid/10/0074633.jpg',\n",
       " 'data_fgvc/valid/10/0139685.jpg',\n",
       " 'data_fgvc/valid/10/0688093.jpg',\n",
       " 'data_fgvc/valid/10/0713645.jpg',\n",
       " 'data_fgvc/valid/10/0809727.jpg',\n",
       " 'data_fgvc/valid/10/0869644.jpg',\n",
       " 'data_fgvc/valid/10/1068733.jpg']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(weight_path):\n",
    "    model_0 = load_model_from(\"trained_model/modelfgvc_sec_0.json\", weight_path)\n",
    "    res = model_0.predict(datas)\n",
    "    return res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39031339,  0.00246694,  0.24623962,  0.99023902,  0.00664667,\n",
       "        0.08404001,  0.87686318,  0.17210899,  0.02940854,  0.0094766 ,\n",
       "        0.98935497,  0.92093688,  0.81629044,  0.82622737], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 2\n",
    "check(\"trained_model/modelfgvc_sec_0-02-0.872.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.60957766e-01,   3.40920151e-03,   3.08307279e-02,\n",
       "         9.85011578e-01,   3.60858347e-03,   4.93161939e-02,\n",
       "         9.92795169e-01,   1.21976174e-01,   3.71880196e-02,\n",
       "         1.83637065e-04,   6.54763103e-01,   1.94192082e-01,\n",
       "         7.86803663e-01,   7.11530149e-01], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 3\n",
    "check(\"trained_model/modelfgvc_sec_0-01-0.845.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.94575262e-01,   3.64112412e-03,   7.46889859e-02,\n",
       "         9.87466872e-01,   5.67003945e-03,   1.41340062e-01,\n",
       "         9.98587906e-01,   2.61859149e-01,   7.36977607e-02,\n",
       "         4.96607448e-04,   8.58851254e-01,   1.38949797e-01,\n",
       "         4.62956578e-01,   9.22738492e-01], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 4\n",
    "check(\"trained_model/modelfgvc_sec_0-02-0.804.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99787402,  0.00530914,  0.04714767,  0.99593902,  0.00302442,\n",
       "        0.13430484,  0.99962211,  0.28590381,  0.08145444,  0.00138246,\n",
       "        0.87990385,  0.18785156,  0.76647055,  0.90059167], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 5\n",
    "check(\"trained_model/modelfgvc_sec_0-03-0.818.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04610051,  0.09499395,  0.6616056 ,  0.95639879,  0.09035208,\n",
       "        0.54387975,  0.86188912,  0.64478827,  0.9523049 ,  0.00184466,\n",
       "        0.70983821,  0.93802178,  0.87476081,  0.49245015], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(\"trained_model/modelfgvc_sec_0-99-0.831.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = FilesPair(*split_files(target_cat, valdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.trues[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/63/0063918.jpg',\n",
       " 'data_fgvc/valid/63/0522914.jpg',\n",
       " 'data_fgvc/valid/63/0917793.jpg',\n",
       " 'data_fgvc/valid/63/0959054.jpg',\n",
       " 'data_fgvc/valid/63/1950704.jpg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.falses[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [path for files in [vals.trues, vals.falses] for path in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
