{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train second set of one vs. rest (OVR) classifiers.\n",
    "\n",
    "We train another set of classifiers that are used for classifications.  \n",
    "These classifiers are trained using similar images for each target class; similarities between classes are computed in *classifier_similarity.ipynb*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH=\"trained_model\"\n",
    "%mkdir -p $BASE_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.modelutils import ModelCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler = ModelCompiler(BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.processor import create_generators\n",
    "\n",
    "TRAIN_DATAGEN, VALID_DATAGEN = create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import dir2filedict_sorted\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load category and file path information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict = dir2filedict_sorted(\"data_fgvc/train\")\n",
    "valdict = dir2filedict_sorted(\"data_fgvc/valid\")\n",
    "categories = [str(i) for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdict['0'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is expected outputs.   \n",
    "All the outputs in {*train.ipynb*, *classifier_similarity.ipynb*, *train_multiclass_classifier.ipynb*, *train_second.ipynb*} must be the same. \n",
    "\n",
    "['data_fgvc/valid/0/0062781.jpg',  \n",
    " 'data_fgvc/valid/0/0113201.jpg',  \n",
    " 'data_fgvc/valid/0/0450014.jpg',  \n",
    " 'data_fgvc/valid/0/0602177.jpg',  \n",
    " 'data_fgvc/valid/0/0716386.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train second level classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class for training second level classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.one_vs_all import OneVsAllModelTrainer\n",
    "from models.modelutils import split_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OneVsAllModelTrainer(TRAIN_DATAGEN, VALID_DATAGEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.one_vs_all import FilesPair, TrValFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondLevelClassifierTrainer:\n",
    "    def __init__(self, base_model_name, basedir, trainer, compiler):\n",
    "        self.base_model_name = base_model_name\n",
    "        self.basedir = basedir\n",
    "\n",
    "        self.compiler = compiler\n",
    "        self.trainer = trainer\n",
    "        \n",
    "    def setup_filedict(self, train_files_dict, valid_files_dict):\n",
    "        self.train_files_dict = train_files_dict\n",
    "        self.valid_files_dict = valid_files_dict\n",
    "        self.valid_files_dict_org = self.valid_files_dict\n",
    "        \n",
    "    def _model_path(self, target_key):\n",
    "        return os.path.join(self.basedir, \"{}_{}\".format(self.base_model_name, target_key))\n",
    "    \n",
    "    def _split_by_set(self, target_key, false_keyset, files_dict):\n",
    "        trues = files_dict[target_key]\n",
    "        falses = [path for key in false_keyset for path in files_dict[key]]\n",
    "        return FilesPair(trues, falses)\n",
    "    \n",
    "    def _split_files(self, targetkey, files_dict):\n",
    "        return FilesPair(*split_files(targetkey, files_dict))\n",
    "    \n",
    "    def train_second_level(self, target_key, highcat_keyset, eachepochs=10, retrainings=1, removecheckpoint=True):\n",
    "        self.trainer.retrainings = retrainings\n",
    "        falseset = highcat_keyset - set(target_key)\n",
    "        trs = self._split_by_set(target_key, falseset, self.train_files_dict)\n",
    "        vals = self._split_by_set(target_key, falseset, self.valid_files_dict)\n",
    "        trvals = TrValFiles(trs, vals)\n",
    "        self._train_one_core(\"sec_\"+target_key, trvals, eachepochs, removecheckpoint)\n",
    "        \n",
    "    def _train_one_setup(self, model_key, trvals):\n",
    "        model_save_path = self._model_path(model_key)\n",
    "\n",
    "        model = self.compiler.generate_compiled_model(model_save_path)\n",
    "        self.trainer.set_model(model)\n",
    "        self.trainer.set_savepath(model_save_path)\n",
    "        self.trainer.set_dataset(trvals)\n",
    "\n",
    "    def _train_one_core(self, model_key, trvals, eachepochs, removecheckpoint):\n",
    "        self._train_one_setup(model_key, trvals)\n",
    "\n",
    "        self.trainer.train_model(eachepochs=eachepochs, hard_coded_steps_per_epoch=(100, 10))\n",
    "        if removecheckpoint:\n",
    "            self.trainer.remove_checkpoint()\n",
    "\n",
    "    def remove_checkpoint(self, model_key):\n",
    "        # utility method for cleaup interrupted case\n",
    "        self.trainer.set_savepath(self._model_path(model_key))\n",
    "        self.trainer.remove_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_trainer = SecondLevelClassifierTrainer(\"modelfgvc\", BASE_MODEL_PATH, trainer, compiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_trainer.setup_filedict(trdict, valdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $ClassSim$ results to gather similar classes for each target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classsim = pd.read_pickle(\"results/valid_sim_df_fgvc.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIM_THRESHOLD = 0.1\n",
    "# This data set is much fine grained. So threshold should be higher. We choose 0.4 for average similary class as about 18.\n",
    "SIM_THRESHOLD = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seconds(keys, eachepochs=5, removecheckpoint=True):\n",
    "    for targetkey in keys:\n",
    "        similarkeyset = set(classsim[targetkey][classsim[targetkey] >= SIM_THRESHOLD].index)\n",
    "        try:\n",
    "            if len(similarkeyset) == 1:\n",
    "                print(\"no similar category. only first classifier is enough. skip second training.\")\n",
    "            else:\n",
    "                sec_trainer.train_second_level(targetkey, similarkeyset, eachepochs=eachepochs, removecheckpoint=removecheckpoint)\n",
    "        except ValueError as e:\n",
    "            print(\"ValueError, skip {0}: {1}\".format(targetkey, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  8/100 [=>............................] - ETA: 10:24 - loss: 0.6801 - acc: 0.5781Epoch 00001: saving model to trained_model/modelfgvc_sec_0-01-0.905.h5\n",
      "  8/100 [=>............................] - ETA: 21:48 - loss: 0.6801 - acc: 0.5781 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 2/2\n",
      "  8/100 [=>............................] - ETA: 8:46 - loss: 0.6507 - acc: 0.6719Epoch 00002: saving model to trained_model/modelfgvc_sec_0-02-0.881.h5\n",
      "  8/100 [=>............................] - ETA: 11:30 - loss: 0.6507 - acc: 0.6719 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 1/2\n",
      "  8/100 [=>............................] - ETA: 10:53 - loss: 0.7033 - acc: 0.5312Epoch 00001: saving model to trained_model/modelfgvc_sec_1-01-0.962.h5\n",
      "  8/100 [=>............................] - ETA: 33:52 - loss: 0.7033 - acc: 0.5312 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 2/2\n",
      "  8/100 [=>............................] - ETA: 8:40 - loss: 0.5557 - acc: 0.7266Epoch 00002: saving model to trained_model/modelfgvc_sec_1-02-0.962.h5\n",
      "  8/100 [=>............................] - ETA: 14:24 - loss: 0.5557 - acc: 0.7266 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 1/2\n",
      "  8/100 [=>............................] - ETA: 11:01 - loss: 0.7057 - acc: 0.5156Epoch 00001: saving model to trained_model/modelfgvc_sec_2-01-0.950.h5\n",
      "  8/100 [=>............................] - ETA: 40:57 - loss: 0.7057 - acc: 0.5156 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 2/2\n",
      "  8/100 [=>............................] - ETA: 8:23 - loss: 0.5810 - acc: 0.6927Epoch 00002: saving model to trained_model/modelfgvc_sec_2-02-0.907.h5\n",
      "  8/100 [=>............................] - ETA: 12:40 - loss: 0.5810 - acc: 0.6927 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 1/2\n",
      "  8/100 [=>............................] - ETA: 11:40 - loss: 0.7403 - acc: 0.5547Epoch 00001: saving model to trained_model/modelfgvc_sec_3-01-0.576.h5\n",
      "  8/100 [=>............................] - ETA: 50:45 - loss: 0.7403 - acc: 0.5547 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 2/2\n",
      "  8/100 [=>............................] - ETA: 8:38 - loss: 0.5901 - acc: 0.7031Epoch 00002: saving model to trained_model/modelfgvc_sec_3-02-0.034.h5\n",
      "  8/100 [=>............................] - ETA: 14:55 - loss: 0.5901 - acc: 0.7031 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 1/2\n",
      "  8/100 [=>............................] - ETA: 12:22 - loss: 0.7114 - acc: 0.5469Epoch 00001: saving model to trained_model/modelfgvc_sec_4-01-0.884.h5\n",
      "  8/100 [=>............................] - ETA: 1:01:45 - loss: 0.7114 - acc: 0.5469 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00Epoch 2/2\n",
      "  2/100 [..............................] - ETA: 9:49 - loss: 0.5308 - acc: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5e3a610cf9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meachepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-1e57bdfdc53c>\u001b[0m in \u001b[0;36mtrain_seconds\u001b[0;34m(keys, eachepochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no similar category. only first classifier is enough. skip second training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0msec_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_second_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarkeyset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meachepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meachepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ValueError, skip {0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d58b75c727c5>\u001b[0m in \u001b[0;36mtrain_second_level\u001b[0;34m(self, target_key, highcat_keyset, eachepochs, retrainings, removecheckpoint)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_by_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalseset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_files_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrValFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sec_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtarget_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meachepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremovecheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_one_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d58b75c727c5>\u001b[0m in \u001b[0;36m_train_one_core\u001b[0;34m(self, model_key, trvals, eachepochs, removecheckpoint)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meachepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meachepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_coded_steps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremovecheckpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/models/one_vs_all.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, eachepochs, batch_size, target_size, hard_coded_steps_per_epoch)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_spe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_seconds(categories[0:], eachepochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether model is property learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cat = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarkeyset = set(classsim[target_cat][classsim[target_cat] >= SIM_THRESHOLD].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarkeyset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '13', '15', '22', '45']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falseset = list(sorted(similarkeyset - set(target_cat)))\n",
    "falseset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import load_best_model_if_exist\n",
    "import os\n",
    "from models.processor import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = load_best_model_if_exist(\"trained_model/modelfgvc_sec_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = valdict['0']+valdict[falseset[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ds.files_to_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_0.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12177239,  0.14247935,  0.13586961,  0.10310103,  0.11975336,\n",
       "        0.29116184,  0.25873953,  0.07083958,  0.05815217,  0.05779626,\n",
       "        0.06138925,  0.05145602,  0.09198892,  0.19282584], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg',\n",
       " 'data_fgvc/valid/0/0869722.jpg',\n",
       " 'data_fgvc/valid/0/1514481.jpg',\n",
       " 'data_fgvc/valid/52/0062226.jpg',\n",
       " 'data_fgvc/valid/52/0136197.jpg',\n",
       " 'data_fgvc/valid/52/0171956.jpg',\n",
       " 'data_fgvc/valid/52/0523171.jpg',\n",
       " 'data_fgvc/valid/52/0523172.jpg',\n",
       " 'data_fgvc/valid/52/0894317.jpg',\n",
       " 'data_fgvc/valid/52/1627560.jpg']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9577Epoch 00001: saving model to trained_model/modelfgvc_sec_0-01-0.845.h5\n",
      "100/100 [==============================] - 151s 2s/step - loss: 0.0962 - acc: 0.9581 - val_loss: 0.4193 - val_acc: 0.8446\n",
      "Epoch 2/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9823Epoch 00002: saving model to trained_model/modelfgvc_sec_0-02-0.804.h5\n",
      "100/100 [==============================] - 78s 779ms/step - loss: 0.0432 - acc: 0.9813 - val_loss: 0.5769 - val_acc: 0.8041\n",
      "Epoch 3/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9722Epoch 00003: saving model to trained_model/modelfgvc_sec_0-03-0.818.h5\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.0686 - acc: 0.9719 - val_loss: 0.6334 - val_acc: 0.8176\n"
     ]
    }
   ],
   "source": [
    "train_seconds(list(categories[0]), eachepochs=3, removecheckpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import load_model_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 2\n",
    "model_0 = load_model_from(\"trained_model/modelfgvc_sec_0.json\", \"trained_model/modelfgvc_sec_0-02-0.872.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_0.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39031339,  0.00246694,  0.24623962,  0.99023902,  0.00664667,\n",
       "        0.08404001,  0.87686318,  0.17210899,  0.02940854,  0.0094766 ,\n",
       "        0.98935497,  0.92093688,  0.81629044,  0.82622737], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg',\n",
       " 'data_fgvc/valid/0/0869722.jpg',\n",
       " 'data_fgvc/valid/0/1514481.jpg',\n",
       " 'data_fgvc/valid/10/0074633.jpg',\n",
       " 'data_fgvc/valid/10/0139685.jpg',\n",
       " 'data_fgvc/valid/10/0688093.jpg',\n",
       " 'data_fgvc/valid/10/0713645.jpg',\n",
       " 'data_fgvc/valid/10/0809727.jpg',\n",
       " 'data_fgvc/valid/10/0869644.jpg',\n",
       " 'data_fgvc/valid/10/1068733.jpg']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(weight_path):\n",
    "    model_0 = load_model_from(\"trained_model/modelfgvc_sec_0.json\", weight_path)\n",
    "    res = model_0.predict(datas)\n",
    "    return res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39031339,  0.00246694,  0.24623962,  0.99023902,  0.00664667,\n",
       "        0.08404001,  0.87686318,  0.17210899,  0.02940854,  0.0094766 ,\n",
       "        0.98935497,  0.92093688,  0.81629044,  0.82622737], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 2\n",
    "check(\"trained_model/modelfgvc_sec_0-02-0.872.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.60957766e-01,   3.40920151e-03,   3.08307279e-02,\n",
       "         9.85011578e-01,   3.60858347e-03,   4.93161939e-02,\n",
       "         9.92795169e-01,   1.21976174e-01,   3.71880196e-02,\n",
       "         1.83637065e-04,   6.54763103e-01,   1.94192082e-01,\n",
       "         7.86803663e-01,   7.11530149e-01], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 3\n",
    "check(\"trained_model/modelfgvc_sec_0-01-0.845.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.94575262e-01,   3.64112412e-03,   7.46889859e-02,\n",
       "         9.87466872e-01,   5.67003945e-03,   1.41340062e-01,\n",
       "         9.98587906e-01,   2.61859149e-01,   7.36977607e-02,\n",
       "         4.96607448e-04,   8.58851254e-01,   1.38949797e-01,\n",
       "         4.62956578e-01,   9.22738492e-01], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 4\n",
    "check(\"trained_model/modelfgvc_sec_0-02-0.804.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99787402,  0.00530914,  0.04714767,  0.99593902,  0.00302442,\n",
       "        0.13430484,  0.99962211,  0.28590381,  0.08145444,  0.00138246,\n",
       "        0.87990385,  0.18785156,  0.76647055,  0.90059167], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch 5\n",
    "check(\"trained_model/modelfgvc_sec_0-03-0.818.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = FilesPair(*split_files(target_cat, valdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.trues[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/63/0063918.jpg',\n",
       " 'data_fgvc/valid/63/0522914.jpg',\n",
       " 'data_fgvc/valid/63/0917793.jpg',\n",
       " 'data_fgvc/valid/63/0959054.jpg',\n",
       " 'data_fgvc/valid/63/1950704.jpg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.falses[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [path for files in [vals.trues, vals.falses] for path in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
