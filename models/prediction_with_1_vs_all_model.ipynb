{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction check using trained model\n",
    "\n",
    "- Set up\n",
    "- Prediction : binary classification prediction\n",
    "- (If you need) Save the predicted images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "# import preprocess func from processor module\n",
    "from processor import preprocess\n",
    "from processor import DataSet\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DATA_DIR=''\n",
    "\n",
    "MODEL_NAME = \"\"\n",
    "CATEGORY_DICT_CSV=os.path.join(BASE_DATA_DIR, \"178_dict.csv\")\n",
    "\n",
    "TEST_DATA_DIRS = [ os.path.join(BASE_DATA_DIR, \"valid\") + \"/*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from category import load_category_dict\n",
    "from category import lookup_index\n",
    "from category import category_matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catdict = load_category_dict(CATEGORY_DICT_CSV)\n",
    "target_index = lookup_index(catdict, '')\n",
    "hamburg_pred = category_matcher(target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataTest(object):\n",
    "    '''\n",
    "    Data preparation for prediction test\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.dataSet = DataSet()\n",
    "    \n",
    "    def get_data_paths(self,dirs):\n",
    "        file_paths = []\n",
    "        for elem in dirs:\n",
    "            paths = glob.glob(os.path.normpath(\"{}/*.jpg\").format(elem))\n",
    "            file_paths.extend(paths)\n",
    "        return file_paths\n",
    "        \n",
    "    def chunked(self, iterable, n):\n",
    "        return [iterable[x:x + n] for x in range(0, len(iterable), n)]\n",
    "    \n",
    "    def preprocess_data(self, file_paths, pred):\n",
    "        test_labels = list(map(pred, file_paths))\n",
    "        test_paths = file_paths\n",
    "        test_data = self.dataSet.files_to_dataset(file_paths)\n",
    "\n",
    "        return test_data, test_labels, test_paths\n",
    "    \n",
    "    def get_N_sample(self, file_paths, N):\n",
    "        import random\n",
    "        index = random.sample(range(len(file_paths)), N)\n",
    "        samples = [file_paths[i] for i in index]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modelutils import load_model\n",
    "class Model(object):\n",
    "    '''\n",
    "    Model loading and prediction methods\n",
    "    '''\n",
    "    def __init__(self, model_prefix):\n",
    "        self.model = load_model(model_prefix)\n",
    "        \n",
    "    def predict_raw(self, data_chunk, batch_size=32):\n",
    "        prediction = self.model.predict(data_chunk, batch_size)\n",
    "        return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visualize import plot_image_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MODEL = Model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATASET = DataTest()\n",
    "DATA_PATHS = TEST_DATASET.get_data_paths(TEST_DATA_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check with small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_paths = TEST_DATASET.get_data_paths(TEST_DATA_DIRS)\n",
    "samples = TEST_DATASET.get_N_sample(DATA_PATHS, 3)\n",
    "\n",
    "test_data, test_label, test_path = TEST_DATASET.preprocess_data(\n",
    "    samples, hamburg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.predict_raw(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = TEST_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "prediction_col = []\n",
    "test_labels = []\n",
    "test_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    test_data_chunk, test_label_chunk, test_path_chunk = TEST_DATASET.preprocess_data(chunk,hamburg_pred)\n",
    "    test_labels.extend(test_label_chunk)\n",
    "    test_paths.extend(test_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_raw(test_data_chunk, batch_size=32)\n",
    "    prediction_col.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_col[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_ONEVS = pd.DataFrame({\n",
    "    'ans' : test_labels,\n",
    "    'class0': [pair[0] for pair in prediction_col],\n",
    "    'class1' : [pair[1] for pair in prediction_col],\n",
    "    'filepaths' : test_paths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(\"trained_model/intermediate\") or os.makedirs(\"trained_model/intermediate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.remove(\"trained_model/intermediate/onevs_2class.dat\")\n",
    "RESULT_ONEVS.to_pickle(\"trained_model/intermediate/onevs_2class_weakcollect.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESULT_ONEVS = pd.read_pickle(\"trained_model/intermediate/onevs.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = labels.sort_values(by=\"class1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "miss classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(labels[0:10][\"filepaths\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highconf = RESULT_ONEVS.sort_values(by=\"class1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(highconf[0:10]['filepaths'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highconf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highconf_miss = highconf.where(highconf[\"ans\"] == False).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highconf_miss[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_image_list(highconf_miss[0:40]['filepaths'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highconf_miss[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep 1 by 3 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_col[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_ONEVS = pd.DataFrame({\n",
    "    'ans' : test_labels,\n",
    "    'class0': [pair[0] for pair in prediction_col],\n",
    "    'class1' : [pair[1] for pair in prediction_col],\n",
    "    'filepaths' : test_paths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(\"trained_model/intermediate\") or os.makedirs(\"trained_model/intermediate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.remove(\"trained_model/intermediate/onevs_2class.dat\")\n",
    "RESULT_ONEVS.to_pickle(\"trained_model/intermediate/onevs_2class.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESULT_ONEVS = pd.read_pickle(\"trained_model/intermediate/onevs.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = labels.sort_values(by=\"class1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg_df(labels, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "miss classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(labels[0:10][\"filepaths\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highconf = RESULT_ONEVS.sort_values(by=\"class1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(highconf[0:10]['filepaths'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highconf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highconf_miss = highconf.where(highconf[\"ans\"] == False).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highconf_miss[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_image_list(highconf_miss[0:40]['filepaths'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.sort_values(by=\"class1\", ascending=False)[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.sort_values(by=\"class1\", ascending=False)[0:100][1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.sort_values(by=\"predictions\", ascending=False)[1:2]['filepaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def checkimg(fpath):\n",
    "    display(Image(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(RESULT_ONEVS.sort_values(by=\"class1\", ascending=False)[0:100][1:2]['filepaths'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.sort_values(by=\"class1\", ascending=False)[0:100][1:2]['filepaths'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = RESULT_ONEVS.where(RESULT_ONEVS['class0']< RESULT_ONEVS['class1']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.where(preds['class1'] > 0.8).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(preds.where(preds['class1'] > 0.8).dropna().iloc[1][\"filepaths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.where(preds['class1'] > 0.9).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = preds.where(preds['class1'] > 0.9).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(tmp.iloc[10][\"filepaths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkimg_df(df, loc):\n",
    "    checkimg(df.iloc[loc][\"filepaths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()['predictions'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == False).dropna()[\"predictions\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()['predictions'].astype(float).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == False).dropna()['predictions'].astype(float).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"predictions\"] > 0.8).dropna()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"predictions\"] > 0.8).dropna().where(RESULT_ONEVS[\"ans\"] == True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"predictions\"] > 0.8).dropna().where(RESULT_ONEVS[\"ans\"] == False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"predictions\"] > 0.5).dropna().where(RESULT_ONEVS[\"ans\"] == True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"predictions\"] > 0.5).dropna().where(RESULT_ONEVS[\"ans\"] == False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is dup to master branch's prediction_with_trained_model.ipynb. Check setup code of that file, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECK_DATA_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataCheck(object):\n",
    "    '''\n",
    "    Data preparation.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_data_paths(self,dirs):\n",
    "        return list(glob.glob(os.path.normpath(\"{}/*.jpg\").format(dirs)))\n",
    "        \n",
    "    def chunked(self, iterable, n):\n",
    "        return [iterable[x:x + n] for x in range(0, len(iterable), n)]\n",
    "    \n",
    "    def preprocess_data(self, file_paths):\n",
    "        test_data = []\n",
    "        test_paths = []\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            img = scipy.misc.imread(file_path)\n",
    "            img = preprocess(img)\n",
    "            test_data.append(img)\n",
    "\n",
    "            test_paths.append(file_path)\n",
    "\n",
    "        test_data = np.array(test_data).astype(np.float32)\n",
    "        test_data = test_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "        return test_data, test_paths\n",
    "    \n",
    "    def get_N_sample(self, file_paths, N):\n",
    "        import random\n",
    "        index = random.sample(range(len(file_paths)), N)\n",
    "        samples = [file_paths[i] for i in index]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECK_DATASET = DataCheck()\n",
    "DATA_PATHS = CHECK_DATASET.get_data_paths(CHECK_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DATA_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = CHECK_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "pred_list = []\n",
    "file_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    check_data_chunk, file_path_chunk = CHECK_DATASET.preprocess_data(chunk)\n",
    "    file_paths.extend(file_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_raw(check_data_chunk, batch_size=32)\n",
    "    pred_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.T[0, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[831]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = prediction.reshape([prediction.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(flatten > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(flatten > 0.5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = np.asarray(file_paths)[np.where(flatten > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = np.asarray(file_paths)[np.where(flatten > 0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = np.asarray(file_paths)[np.where(flatten > 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(np.asarray(file_paths)[np.where(flatten > 0.5)][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obsolete try and error code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = RESULT_ONEVS.sort_values(by=\"predictions\", ascending=False)[0:100]['filepaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = map(hamburg_pred, DATA_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hambrugpaths = [f for label, f in zip(labels, DATA_PATHS) if label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hambrugpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hambrugpaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(hambrugpaths[116])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()['filepaths'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(files.iloc[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checkimg(RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()['filepaths'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_paths = TEST_DATASET.get_data_paths(TEST_DATA_DIRS)\n",
    "samples = TEST_DATASET.get_N_sample(DATA_PATHS, 3)\n",
    "\n",
    "test_data, test_label, test_path = TEST_DATASET.preprocess_data(\n",
    "    samples, hamburg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == False).dropna()[\"predictions\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "np.sum( RESULT_SINGLE['ans'] == RESULT_SINGLE['predictions'] ) / len(RESULT_SINGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw_cofusion_matrix(RESULT_SINGLE, CATEGORY_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the misclassified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truthdf = RESULT_ONEVS.where(RESULT_ONEVS[\"ans\"] == True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truthdf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(truthdf[0:5]['filepaths'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkimg(truthdf[0:5]['filepaths'].values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat_dict(path):\n",
    "    catdf = pd.read_csv(path)\n",
    "    return {idx:catdf[catdf['idx']==idx]['name'].values[0] for idx in catdf['idx']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_dict = get_cat_dict(CATEGORY_DICT_CSV)\n",
    "cat_dict_pair = (CATEGORY_DICT, cat_dict)\n",
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_key_from_value(dictpair, idx):\n",
    "    '''\n",
    "    input : pair of category dictonary (idx_to_idxname, idxname_to_catname) and index\n",
    "    output : key (category name) of corresponding index\n",
    "    '''\n",
    "    idx_to_idxname_dict = dictpair[0]\n",
    "    key = list(idx_to_idxname_dict.keys())[\n",
    "        list( idx_to_idxname_dict.values() ).index(idx)\n",
    "    ]\n",
    "    return dictpair[1][int(key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_key_from_value((CATEGORY_DICT, cat_dict), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_DICT[\"100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_filtered_by_ans(df,dictpair,idx,num_display):\n",
    "    '''\n",
    "    input : result dataframe, category dictionary, index of class, num of displaying images\n",
    "    output : plot of images (correct - prediction pairs)\n",
    "    '''\n",
    "    ans_key = get_key_from_value(dictpair,idx)\n",
    "    \n",
    "    plt.ion()\n",
    "    idx_to_idxname_dict = dictpair[0]\n",
    "    \n",
    "    for i in range(len(idx_to_idxname_dict)):\n",
    "        pred_key = get_key_from_value(dictpair,i)\n",
    "        \n",
    "        #Get dataframe\n",
    "        miss_img_paths = df.where( \n",
    "            df['ans'] == idx\n",
    "        ).dropna().where(\n",
    "            df['predictions'] == i\n",
    "        ).dropna()['filepaths']\n",
    "        \n",
    "        #Transform it into a list\n",
    "        miss_img_paths = [elem for elem in miss_img_paths]\n",
    "        \n",
    "        plt.figure(figsize = (10,17))\n",
    "        gs1 = gridspec.GridSpec(1,num_display)\n",
    "        gs1.update(wspace=0.025, hspace=0.05)\n",
    "        \n",
    "        print(\"ans:{0} - pred:{1}\".format(ans_key,pred_key))\n",
    "        for i in range(num_display):\n",
    "            ax1 = plt.subplot(gs1[i])\n",
    "            plt.axis('on')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.set_aspect('equal')\n",
    "            try:\n",
    "                image = plt.imread(miss_img_paths[i])\n",
    "                plt.imshow(image)\n",
    "            except:\n",
    "                pass\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_filtered_by_ans(RESULT_SINGLE, (CATEGORY_DICT, cat_dict), 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Check : Multi classes case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = TEST_DATASET.chunked(DATA_PATHS, 4000)\n",
    "\n",
    "PREDICTIONS_MULTI = []\n",
    "test_labels = []\n",
    "test_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    test_data_chunk, test_label_chunk, test_path_chunk = TEST_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    test_labels.extend(test_label_chunk)\n",
    "    test_paths.extend(test_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_multiclass(test_data_chunk, batch_size=32)\n",
    "    PREDICTIONS_MULTI.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = [ ans in pred for ans,pred in zip(test_labels, PREDICTIONS_MULTI) ]\n",
    "print( sum(matched) / len(matched) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_predicted_num(predictions):\n",
    "    '''\n",
    "    input : multiclass predictions\n",
    "    output : the number of predictions for each class\n",
    "    '''\n",
    "    from collections import Counter\n",
    "    \n",
    "    counter = Counter( [elem for sublist in predictions for elem in sublist] )\n",
    "    pred_count = counter.most_common()\n",
    "    pred_count = sorted(pred_count, key=lambda x: x[0])\n",
    "    \n",
    "    return pred_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_predicted_num(PREDICTIONS_MULTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_ratio_in_preds(predictions, test_labels):\n",
    "    '''\n",
    "    input : multiclass predictions and answer labels\n",
    "    output : correct ratio in each prediction\n",
    "    '''\n",
    "    correct_pred_ratio = []\n",
    "    pred_count = count_predicted_num(predictions)\n",
    "    \n",
    "    for pred_cls, pred_num in pred_count:\n",
    "        matched_num = [ (ans in pred) and (pred_cls in pred) \n",
    "                       for ans,pred in zip(test_labels, predictions)\n",
    "                      ]\n",
    "        \n",
    "        correct_pred_ratio.append( \n",
    "            (get_key_from_value(CATEGORY_DICT, pred_cls), sum(matched_num)/pred_num) \n",
    "        )\n",
    "    \n",
    "    return correct_pred_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ratio_in_preds(PREDICTIONS_MULTI, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(preds) for preds in PREDICTIONS_MULTI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([len(preds) for preds in PREDICTIONS_MULTI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched_tupple = [ (idx, ans, pred) \n",
    "               for idx, ans,pred in zip(range(len(test_labels)), test_labels, PREDICTIONS_MULTI)\n",
    "               if (ans in pred)\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missed_tupple = [ (idx, ans, pred) \n",
    "               for idx, ans,pred in zip(range(len(test_labels)), test_labels, PREDICTIONS_MULTI)\n",
    "               if (ans not in pred)\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matched_tupple), len(missed_tupple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_missmatch(missedtups, filepaths, catdictpair, cattarget,num_display):\n",
    "    '''\n",
    "    input : list of missed data tupple (idx, label, [missed]), category dictionary, index of class which you want to show, num of displaying images\n",
    "    output : plot of images (correct - prediction pairs)\n",
    "    '''\n",
    "    ans_key = get_key_from_value(catdictpair,cattarget)\n",
    "    \n",
    "    plt.ion()\n",
    "    \n",
    "    targets = [(idx, lab, preds) for idx, lab, preds in missedtups if lab == cattarget]\n",
    "    \n",
    "    for i in range(num_display):\n",
    "        if(len(targets) <= i):\n",
    "            print(\"too small missed: {0}, {1}\".format(len(targets), i))\n",
    "            return\n",
    "        tup = targets[i]\n",
    "        pcat_names = [get_key_from_value(catdictpair, pcat) for pcat in tup[2]]\n",
    "        print(\"ans:{0} - pred:{1}\".format(ans_key, \", \".join(pcat_names)))\n",
    "    \n",
    "        idx = tup[0]\n",
    "        miss_img_path = filepaths[idx]\n",
    "        \n",
    "        plt.axis('on')\n",
    "        # plt.set_xticklabels([])\n",
    "        # plt.set_yticklabels([])\n",
    "        #plt.set_aspect('equal')\n",
    "        try:\n",
    "            image = plt.imread(miss_img_path)\n",
    "            plt.imshow(image)\n",
    "        except:\n",
    "                pass\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_missmatch(missed_tupple, test_paths, (CATEGORY_DICT, cat_dict), 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_missmatch(missed_tupple, test_paths, (CATEGORY_DICT, cat_dict), 15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Save the predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def save_predicted_image(org_data_path, save_base_dir, result):\n",
    "#     '''\n",
    "#     input : \n",
    "#         org_data_path - test data dir\n",
    "#         , save_base_dir - save dir\n",
    "#         , result - sngle prediction result dataframe\n",
    "#     output : copy the images to save dir with {ans, pred} pairs\n",
    "#     '''\n",
    "#     import shutil\n",
    "    \n",
    "#     categories = [elem.split(\"/\")[-1] for elem in glob.glob(org_data_path)]\n",
    "#     os.mkdir(save_base_dir) if not os.path.isdir(save_base_dir) else None\n",
    "    \n",
    "#     #Create directories for saving\n",
    "#     for category in categories:\n",
    "#         ans_category_dir = \"{0}/{1}\".format(save_base_dir, category)\n",
    "#         os.mkdir(ans_category_dir) if not os.path.isdir(ans_category_dir) else None\n",
    "        \n",
    "#         for i_category in categories:\n",
    "#             ans_pred_category_dir = \"{0}/{1}\".format(ans_category_dir, i_category)\n",
    "#             os.mkdir(ans_pred_category_dir) if not os.path.isdir(ans_pred_category_dir) else None\n",
    "    \n",
    "#     #Save the images\n",
    "#     for ans_v in range(len(CATEGORY_DICT)):\n",
    "#         ans_df = result[result['ans'] == ans_v]\n",
    "#         ans_k = get_key_from_value(CATEGORY_DICT,ans_v)\n",
    "    \n",
    "#         for pred_v in range(len(CATEGORY_DICT)):\n",
    "#             pred_df = ans_df[ans_df['predictions'] == pred_v]\n",
    "#             pred_k = get_key_from_value(CATEGORY_DICT,pred_v)\n",
    "        \n",
    "#             save_dir = \"{0}/{1}/{2}\".format(save_base_dir, ans_k, pred_k)\n",
    "        \n",
    "#             for filepath in pred_df['filepaths']:\n",
    "#                 filename = filepath.split(\"/\")[-1]\n",
    "#                 shutil.copyfile(filepath, \"{0}/{1}\".format(save_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# save_predicted_image(\n",
    "#     \"./data/test/*\", \"./pred_result/\", RESULT_SINGLE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below codes are copied from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = [\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akagi.data_sources import RedshiftDataSource\n",
    "from cooking_log_image_fetcher import Fetcher\n",
    "from scipy.misc import imread\n",
    "import os\n",
    "\n",
    "\n",
    "def build_condition(users):\n",
    "    conditions = []\n",
    "\n",
    "    for row in users:\n",
    "        conditions.append(\"\"\"\n",
    "            (\n",
    "            )\n",
    "        \"\"\".format(**row))\n",
    "\n",
    "    return ' or '.join(conditions)\n",
    "\n",
    "\n",
    "def fetch_cooking_log_thumbnail(users):\n",
    "    with RedshiftDataSource.for_query(\n",
    "        \"\"\"\n",
    "        ) as ds:\n",
    "\n",
    "        for row in ds:\n",
    "            upload_id, _, user_id = int(row[0]), int(row[1]), int(row[2])\n",
    "            body = Fetcher.fetch_thumbnail(user_id, upload_id, env='production')\n",
    "            image = imread(body)\n",
    "            yield body, image, upload_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('awskeys.txt', 'r') as outfile:\n",
    "    dic = json.load(outfile)\n",
    "AWS_KEY_ID = dic[\"AWS_KEY_ID\"]\n",
    "AWS_SECRET_KEY = dic[\"AWS_SECRET_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (AWS_KEY_ID is not None) and (AWS_SECRET_KEY is not None), \"SET your keys.\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_KEY\n",
    "\n",
    "for body, image, upload_id in fetch_cooking_log_thumbnail(users):\n",
    "\n",
    "    output_filename = \"%s/%s.jpg\" % (output_dir, upload_id)\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        f.write(body.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECK_DATA_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATHS = list(glob.glob(os.path.normpath(\"{}/*.jpg\").format(CHECK_DATA_DIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_data = dataset.files_to_dataset(DATA_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = MODEL.predict_raw(check_data)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_CHECK = pd.DataFrame({\n",
    "    'class0': [pair[0] for pair in arr],\n",
    "    'class1' : [pair[1] for pair in arr],\n",
    "    'filepaths' : DATA_PATHS\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_CHECK.sort_values(by=\"class1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high = RESULT_CHECK.sort_values(by=\"class1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(high.where(high[\"class1\"] > 0.5).dropna()[\"filepaths\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_image_list(high.where(high[\"class1\"] > 0.7).dropna()[\"filepaths\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = CHECK_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "pred_list = []\n",
    "file_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    check_data_chunk, file_path_chunk = CHECK_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    file_paths.extend(file_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_raw(check_data_chunk, batch_size=32)\n",
    "    pred_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[max(arg) for arg in prediction[0:30, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxs = [max(arg) for arg in prediction[:, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['files'] = file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[0][0:178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[0][178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['maxval'] = pred_df.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['argmax'] = pred_df.iloc[:, 0:178].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visualize import plot_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_df.columns[180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pred_df.where(pred_df['argmax'] == 0).dropna()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[[1, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_5(df, catdictpair):\n",
    "    CATNUM = df.shape[1] - 3 # files, maxval, argmax\n",
    "    for i in range(len(df)):\n",
    "        trans = df.iloc[i, 0:CATNUM].T.astype(float)\n",
    "        top5 = trans.nlargest(5)\n",
    "        respairs = [\"{0}:{1:.3f}\".format(get_key_from_value(catdictpair, idx), top5[idx]) for idx in top5.index]\n",
    "        print(\":\".join((\",\".join(respairs), df['files'].values[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_df_by_category(df, catdictpair, cattarget):\n",
    "    '''\n",
    "    input : prediction result df, category dictionary, index of class which you want to show, num of displaying images\n",
    "    output : plot of images (correct - prediction pairs)\n",
    "    '''\n",
    "    cat_name = get_key_from_value(catdictpair,cattarget)    \n",
    "    \n",
    "    catdf = df.where( \n",
    "            df['argmax'] == cattarget\n",
    "        ).dropna()\n",
    "    \n",
    "    \n",
    "    print(\"category: {}\".format(cat_name))\n",
    "    print_top_5(catdf, catdictpair)\n",
    "    plot_image_list(catdf['files'].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def checkimg(fpath):\n",
    "    display(Image(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_DIST = './result_classified_07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "filtered_df = pred_df.where( \n",
    "            pred_df['maxval'] >= threshold\n",
    "        ).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_catidx_from_value(catdic, idx):\n",
    "    '''\n",
    "    input : category dictonary and index\n",
    "    output : key (category int value) of corresponding index\n",
    "    '''\n",
    "    idx_to_idxname_dict = catdic\n",
    "    key = list(idx_to_idxname_dict.keys())[\n",
    "        list( idx_to_idxname_dict.values() ).index(idx)\n",
    "    ]\n",
    "    return int(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, row in filtered_df.iterrows():\n",
    "    cat = row['argmax']\n",
    "    catname = get_key_from_value(cat_dict_pair, cat)\n",
    "    cat_path = os.path.join(RESULT_DIST, catname)\n",
    "    if not os.path.isdir(cat_path.encode('utf_8')):\n",
    "        os.makedirs(cat_path.encode('utf_8'))\n",
    "    orgpath = row['files']\n",
    "    shutil.copyfile(orgpath, os.path.join(cat_path, os.path.basename(orgpath)).encode('utf_8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = CHECK_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "PREDICTIONS_SINGLE = []\n",
    "file_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    check_data_chunk, file_path_chunk = CHECK_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    file_paths.extend(file_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_oneclass(check_data_chunk, batch_size=32)\n",
    "    PREDICTIONS_SINGLE.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_SINGLE = pd.DataFrame({\n",
    "    'predictions' : PREDICTIONS_SINGLE,\n",
    "    'filepaths' : file_paths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in filtered_df.iterrows():\n",
    "    cat = row['argmax']\n",
    "    catname = get_key_from_value(cat_dict_pair, cat)\n",
    "    catint = get_catidx_from_value(CATEGORY_DICT, cat)\n",
    "    cat_path = os.path.join(RESULT_DIST, str(catint))\n",
    "    if not os.path.isdir(cat_path):\n",
    "        os.makedirs(cat_path)\n",
    "        with open(os.path.join(cat_path, 'category_name.txt'), 'w') as f:\n",
    "            f.write(catname.encode('utf_8'))\n",
    "    orgpath = row['files']\n",
    "    shutil.copyfile(orgpath, os.path.join(cat_path, os.path.basename(orgpath)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
