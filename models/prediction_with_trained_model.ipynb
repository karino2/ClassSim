{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction check using trained model\n",
    "\n",
    "- Set up\n",
    "- Prediction : single label prediction\n",
    "- Prediction : multi label prediction\n",
    "- (If you need) Save the predicted images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "# import preprocess func from processor module\n",
    "from processor import preprocess\n",
    "from processor import DataSet\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DATA_DIR=''\n",
    "\n",
    "MODEL_NAME = \"\"\n",
    "CATEGORY_DICT_CSV=os.path.join(BASE_DATA_DIR, \"\")\n",
    "\n",
    "TEST_DATA_DIRS = [ os.path.join(BASE_DATA_DIR, \"valid\") + \"/*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVEDIR=\"trained_model_latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataTest(object):\n",
    "    '''\n",
    "    Data preparation for prediction test\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.dataSet = DataSet()\n",
    "    \n",
    "    def get_data_paths(self,dirs):\n",
    "        file_paths = []\n",
    "        for elem in dirs:\n",
    "            paths = glob.glob(os.path.normpath(\"{}/*.jpg\").format(elem))\n",
    "            file_paths.extend(paths)\n",
    "        return file_paths\n",
    "        \n",
    "    def chunked(self, iterable, n):\n",
    "        return [iterable[x:x + n] for x in range(0, len(iterable), n)]\n",
    "    \n",
    "    def preprocess_data(self, file_paths, category_dict):\n",
    "        \n",
    "        def path_to_label(path):\n",
    "            label = path.split('/')[-2]\n",
    "            return category_dict[label]\n",
    "        \n",
    "        test_labels = list(map(path_to_label, file_paths))\n",
    "        test_data = self.dataSet.files_to_dataset(file_paths)\n",
    "        test_paths = file_paths\n",
    "        \n",
    "        return test_data, test_labels, test_paths\n",
    "    \n",
    "    def get_N_sample(self, file_paths, N):\n",
    "        import random\n",
    "        index = random.sample(range(len(file_paths)), N)\n",
    "        samples = [file_paths[i] for i in index]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    '''\n",
    "    Model loading and prediction methods\n",
    "    '''\n",
    "    def __init__(self, model_prefix):\n",
    "        with open(\"{}.json\".format(model_prefix), 'r') as f:\n",
    "            self.model = model_from_json(f.read())\n",
    "        self.model.load_weights(\"{}.h5\".format(model_prefix))\n",
    "        with open(\"{}-labels.json\".format(model_prefix), 'r') as f:\n",
    "            self.category_dict = json.load(f)\n",
    "    \n",
    "    def get_category_dict(self):\n",
    "        return self.category_dict\n",
    "        \n",
    "    def predict_raw(self, data_chunk, batch_size=32):\n",
    "        prediction = self.model.predict(data_chunk, batch_size)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_oneclass(self, data_chunk, batch_size=32):\n",
    "        prediction = self.predict_raw(data_chunk)\n",
    "        prediction_label = [ np.argmax(elem) for elem in prediction ]\n",
    "        return prediction_label\n",
    "    \n",
    "    def predict_multiclass(self, data_chunk, thrld=None, batch_size=32):\n",
    "        prediction = self.predict_raw(data_chunk)\n",
    "        \n",
    "        if not thrld:\n",
    "            category_num = len(self.category_dict)\n",
    "            thrld = 1 / category_num\n",
    "        \n",
    "        prediction_labels = [ \n",
    "            [idx for idx,prob in sorted(enumerate(elem), key=lambda x: x[1]) if prob > thrld] \n",
    "            if np.max(elem) > thrld else [np.argmax(elem)] for elem in prediction\n",
    "        ]\n",
    "        \n",
    "        return prediction_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and create test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MODEL = Model(MODEL_NAME)\n",
    "CATEGORY_DICT = MODEL.get_category_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATASET = DataTest()\n",
    "DATA_PATHS = TEST_DATASET.get_data_paths(TEST_DATA_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check with small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATASET = DataTest()\n",
    "data_paths = TEST_DATASET.get_data_paths(TEST_DATA_DIRS)\n",
    "samples = TEST_DATASET.get_N_sample(DATA_PATHS, 3)\n",
    "\n",
    "test_data, test_label, test_path = TEST_DATASET.preprocess_data(\n",
    "    samples, MODEL.get_category_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.predict_raw(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.predict_oneclass(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.predict_multiclass(test_data, thrld=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction Check : Single class case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_cofusion_matrix(result, category_dict):\n",
    "    '''\n",
    "    input : prediction result as a DF and category dictionary\n",
    "    output : plot of confusion matrix\n",
    "    '''\n",
    "    #Compute confusion matrix\n",
    "    conf_arr = confusion_matrix(result['ans'],result['predictions'])\n",
    "    #Get category names in the order of category values\n",
    "    sorted_categories = sorted(category_dict.items(), key=lambda x:x[1])\n",
    "    labels = [ elem[0] for elem in sorted_categories ]\n",
    "    \n",
    "    #Compute normalized confusion matrix for coloring\n",
    "    norm_conf = []\n",
    "    for i in conf_arr:\n",
    "        a = 0\n",
    "        tmp_arr = []\n",
    "        a = sum(i, 0)\n",
    "        for j in i:\n",
    "            tmp_arr.append(float(j)/float(a))\n",
    "        norm_conf.append(tmp_arr)\n",
    "    \n",
    "    #Draw figure\n",
    "    fig = plt.figure()\n",
    "    plt.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                    interpolation='nearest')\n",
    "\n",
    "    width, height = conf_arr.shape\n",
    "\n",
    "    plt.xticks(range(len(category_dict)), labels, rotation='vertical')\n",
    "    plt.yticks(range(len(category_dict)), labels)\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = TEST_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "PREDICTIONS_SINGLE = []\n",
    "test_labels = []\n",
    "test_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    test_data_chunk, test_label_chunk, test_path_chunk = TEST_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    test_labels.extend(test_label_chunk)\n",
    "    test_paths.extend(test_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_oneclass(test_data_chunk, batch_size=32)\n",
    "    PREDICTIONS_SINGLE.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_SINGLE = pd.DataFrame({\n",
    "    'ans' : test_labels,\n",
    "    'predictions' : PREDICTIONS_SINGLE,\n",
    "    'filepaths' : test_paths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_SINGLE[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "np.sum( RESULT_SINGLE['ans'] == RESULT_SINGLE['predictions'] ) / len(RESULT_SINGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw_cofusion_matrix(RESULT_SINGLE, CATEGORY_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the misclassified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat_dict(path):\n",
    "    catdf = pd.read_csv(path)\n",
    "    return {idx:catdf[catdf['idx']==idx]['name'].values[0] for idx in catdf['idx']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_dict = get_cat_dict(CATEGORY_DICT_CSV)\n",
    "cat_dict_pair = (CATEGORY_DICT, cat_dict)\n",
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_key_from_value(dictpair, idx):\n",
    "    '''\n",
    "    input : pair of category dictonary (idx_to_idxname, idxname_to_catname) and index\n",
    "    output : key (category name) of corresponding index\n",
    "    '''\n",
    "    idx_to_idxname_dict = dictpair[0]\n",
    "    key = list(idx_to_idxname_dict.keys())[\n",
    "        list( idx_to_idxname_dict.values() ).index(idx)\n",
    "    ]\n",
    "    return dictpair[1][int(key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_key_from_value((CATEGORY_DICT, cat_dict), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_DICT[\"100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_filtered_by_ans(df,dictpair,idx,num_display):\n",
    "    '''\n",
    "    input : result dataframe, category dictionary, index of class, num of displaying images\n",
    "    output : plot of images (correct - prediction pairs)\n",
    "    '''\n",
    "    ans_key = get_key_from_value(dictpair,idx)\n",
    "    \n",
    "    plt.ion()\n",
    "    idx_to_idxname_dict = dictpair[0]\n",
    "    \n",
    "    for i in range(len(idx_to_idxname_dict)):\n",
    "        pred_key = get_key_from_value(dictpair,i)\n",
    "        \n",
    "        #Get dataframe\n",
    "        miss_img_paths = df.where( \n",
    "            df['ans'] == idx\n",
    "        ).dropna().where(\n",
    "            df['predictions'] == i\n",
    "        ).dropna()['filepaths']\n",
    "        \n",
    "        #Transform it into a list\n",
    "        miss_img_paths = [elem for elem in miss_img_paths]\n",
    "        \n",
    "        plt.figure(figsize = (10,17))\n",
    "        gs1 = gridspec.GridSpec(1,num_display)\n",
    "        gs1.update(wspace=0.025, hspace=0.05)\n",
    "        \n",
    "        print(\"ans:{0} - pred:{1}\".format(ans_key,pred_key))\n",
    "        for i in range(num_display):\n",
    "            ax1 = plt.subplot(gs1[i])\n",
    "            plt.axis('on')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.set_aspect('equal')\n",
    "            try:\n",
    "                image = plt.imread(miss_img_paths[i])\n",
    "                plt.imshow(image)\n",
    "            except:\n",
    "                pass\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_filtered_by_ans(RESULT_SINGLE, (CATEGORY_DICT, cat_dict), 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Check : Multi classes case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = TEST_DATASET.chunked(DATA_PATHS, 4000)\n",
    "\n",
    "PREDICTIONS_MULTI = []\n",
    "test_labels = []\n",
    "test_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    test_data_chunk, test_label_chunk, test_path_chunk = TEST_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    test_labels.extend(test_label_chunk)\n",
    "    test_paths.extend(test_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_multiclass(test_data_chunk, batch_size=32)\n",
    "    PREDICTIONS_MULTI.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = [ ans in pred for ans,pred in zip(test_labels, PREDICTIONS_MULTI) ]\n",
    "print( sum(matched) / len(matched) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_predicted_num(predictions):\n",
    "    '''\n",
    "    input : multiclass predictions\n",
    "    output : the number of predictions for each class\n",
    "    '''\n",
    "    from collections import Counter\n",
    "    \n",
    "    counter = Counter( [elem for sublist in predictions for elem in sublist] )\n",
    "    pred_count = counter.most_common()\n",
    "    pred_count = sorted(pred_count, key=lambda x: x[0])\n",
    "    \n",
    "    return pred_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_predicted_num(PREDICTIONS_MULTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_ratio_in_preds(predictions, test_labels):\n",
    "    '''\n",
    "    input : multiclass predictions and answer labels\n",
    "    output : correct ratio in each prediction\n",
    "    '''\n",
    "    correct_pred_ratio = []\n",
    "    pred_count = count_predicted_num(predictions)\n",
    "    \n",
    "    for pred_cls, pred_num in pred_count:\n",
    "        matched_num = [ (ans in pred) and (pred_cls in pred) \n",
    "                       for ans,pred in zip(test_labels, predictions)\n",
    "                      ]\n",
    "        \n",
    "        correct_pred_ratio.append( \n",
    "            (get_key_from_value(CATEGORY_DICT, pred_cls), sum(matched_num)/pred_num) \n",
    "        )\n",
    "    \n",
    "    return correct_pred_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ratio_in_preds(PREDICTIONS_MULTI, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(preds) for preds in PREDICTIONS_MULTI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([len(preds) for preds in PREDICTIONS_MULTI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched_tupple = [ (idx, ans, pred) \n",
    "               for idx, ans,pred in zip(range(len(test_labels)), test_labels, PREDICTIONS_MULTI)\n",
    "               if (ans in pred)\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missed_tupple = [ (idx, ans, pred) \n",
    "               for idx, ans,pred in zip(range(len(test_labels)), test_labels, PREDICTIONS_MULTI)\n",
    "               if (ans not in pred)\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matched_tupple), len(missed_tupple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_missmatch(missedtups, filepaths, catdictpair, cattarget,num_display):\n",
    "    '''\n",
    "    input : list of missed data tupple (idx, label, [missed]), category dictionary, index of class which you want to show, num of displaying images\n",
    "    output : plot of images (correct - prediction pairs)\n",
    "    '''\n",
    "    ans_key = get_key_from_value(catdictpair,cattarget)\n",
    "    \n",
    "    plt.ion()\n",
    "    \n",
    "    targets = [(idx, lab, preds) for idx, lab, preds in missedtups if lab == cattarget]\n",
    "    \n",
    "    for i in range(num_display):\n",
    "        if(len(targets) <= i):\n",
    "            print(\"too small missed: {0}, {1}\".format(len(targets), i))\n",
    "            return\n",
    "        tup = targets[i]\n",
    "        pcat_names = [get_key_from_value(catdictpair, pcat) for pcat in tup[2]]\n",
    "        print(\"ans:{0} - pred:{1}\".format(ans_key, \", \".join(pcat_names)))\n",
    "    \n",
    "        idx = tup[0]\n",
    "        miss_img_path = filepaths[idx]\n",
    "        \n",
    "        plt.axis('on')\n",
    "        # plt.set_xticklabels([])\n",
    "        # plt.set_yticklabels([])\n",
    "        #plt.set_aspect('equal')\n",
    "        try:\n",
    "            image = plt.imread(miss_img_path)\n",
    "            plt.imshow(image)\n",
    "        except:\n",
    "                pass\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_missmatch(missed_tupple, test_paths, (CATEGORY_DICT, cat_dict), 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_missmatch(missed_tupple, test_paths, (CATEGORY_DICT, cat_dict), 15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Save the predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def save_predicted_image(org_data_path, save_base_dir, result):\n",
    "#     '''\n",
    "#     input : \n",
    "#         org_data_path - test data dir\n",
    "#         , save_base_dir - save dir\n",
    "#         , result - sngle prediction result dataframe\n",
    "#     output : copy the images to save dir with {ans, pred} pairs\n",
    "#     '''\n",
    "#     import shutil\n",
    "    \n",
    "#     categories = [elem.split(\"/\")[-1] for elem in glob.glob(org_data_path)]\n",
    "#     os.mkdir(save_base_dir) if not os.path.isdir(save_base_dir) else None\n",
    "    \n",
    "#     #Create directories for saving\n",
    "#     for category in categories:\n",
    "#         ans_category_dir = \"{0}/{1}\".format(save_base_dir, category)\n",
    "#         os.mkdir(ans_category_dir) if not os.path.isdir(ans_category_dir) else None\n",
    "        \n",
    "#         for i_category in categories:\n",
    "#             ans_pred_category_dir = \"{0}/{1}\".format(ans_category_dir, i_category)\n",
    "#             os.mkdir(ans_pred_category_dir) if not os.path.isdir(ans_pred_category_dir) else None\n",
    "    \n",
    "#     #Save the images\n",
    "#     for ans_v in range(len(CATEGORY_DICT)):\n",
    "#         ans_df = result[result['ans'] == ans_v]\n",
    "#         ans_k = get_key_from_value(CATEGORY_DICT,ans_v)\n",
    "    \n",
    "#         for pred_v in range(len(CATEGORY_DICT)):\n",
    "#             pred_df = ans_df[ans_df['predictions'] == pred_v]\n",
    "#             pred_k = get_key_from_value(CATEGORY_DICT,pred_v)\n",
    "        \n",
    "#             save_dir = \"{0}/{1}/{2}\".format(save_base_dir, ans_k, pred_k)\n",
    "        \n",
    "#             for filepath in pred_df['filepaths']:\n",
    "#                 filename = filepath.split(\"/\")[-1]\n",
    "#                 shutil.copyfile(filepath, \"{0}/{1}\".format(save_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# save_predicted_image(\n",
    "#     \"./data/test/*\", \"./pred_result/\", RESULT_SINGLE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = [\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akagi.data_sources import RedshiftDataSource\n",
    "from cooking_log_image_fetcher import Fetcher\n",
    "from scipy.misc import imread\n",
    "import os\n",
    "\n",
    "\n",
    "def build_condition(users):\n",
    "    conditions = []\n",
    "\n",
    "    for row in users:\n",
    "        conditions.append(\"\"\"\n",
    "            (\n",
    "            )\n",
    "        \"\"\".format(**row))\n",
    "\n",
    "    return ' or '.join(conditions)\n",
    "\n",
    "\n",
    "def fetch_cooking_log_thumbnail(users):\n",
    "    with RedshiftDataSource.for_query(\n",
    "        \"\"\"\n",
    "        \"\"\".format(condition=build_condition(users)),\n",
    "        ) as ds:\n",
    "\n",
    "        for row in ds:\n",
    "            upload_id, _, user_id = int(row[0]), int(row[1]), int(row[2])\n",
    "            body = Fetcher.fetch_thumbnail(user_id, upload_id, env='production')\n",
    "            image = imread(body)\n",
    "            yield body, image, upload_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('awskeys.txt', 'r') as outfile:\n",
    "    dic = json.load(outfile)\n",
    "AWS_KEY_ID = dic[\"AWS_KEY_ID\"]\n",
    "AWS_SECRET_KEY = dic[\"AWS_SECRET_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (AWS_KEY_ID is not None) and (AWS_SECRET_KEY is not None), \"SET your keys.\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_KEY\n",
    "\n",
    "for body, image, upload_id in fetch_cooking_log_thumbnail(users):\n",
    "\n",
    "    output_filename = \"%s/%s.jpg\" % (output_dir, upload_id)\n",
    "    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        f.write(body.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECK_DATA_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataCheck(object):\n",
    "    '''\n",
    "    Data preparation for prediction data.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_data_paths(self,dirs):\n",
    "        return list(glob.glob(os.path.normpath(\"{}/*.jpg\").format(dirs)))\n",
    "        \n",
    "    def chunked(self, iterable, n):\n",
    "        return [iterable[x:x + n] for x in range(0, len(iterable), n)]\n",
    "    \n",
    "    def preprocess_data(self, file_paths, category_dict):\n",
    "        test_data = []\n",
    "        test_paths = []\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            img = scipy.misc.imread(file_path)\n",
    "            img = preprocess(img)\n",
    "            test_data.append(img)\n",
    "\n",
    "            test_paths.append(file_path)\n",
    "\n",
    "        test_data = np.array(test_data).astype(np.float32)\n",
    "        test_data = test_data.transpose((0, 1, 2, 3))\n",
    "\n",
    "        return test_data, test_paths\n",
    "    \n",
    "    def get_N_sample(self, file_paths, N):\n",
    "        import random\n",
    "        index = random.sample(range(len(file_paths)), N)\n",
    "        samples = [file_paths[i] for i in index]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHECK_DATASET = DataCheck()\n",
    "DATA_PATHS = CHECK_DATASET.get_data_paths(CHECK_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = MODEL.predict_raw(check_data)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = CHECK_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "pred_list = []\n",
    "file_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    check_data_chunk, file_path_chunk = CHECK_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    file_paths.extend(file_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_raw(check_data_chunk, batch_size=32)\n",
    "    pred_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[max(arg) for arg in prediction[0:30, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxs = [max(arg) for arg in prediction[:, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.hist(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['files'] = file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[0][0:178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[0][178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['maxval'] = pred_df.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['argmax'] = pred_df.iloc[:, 0:178].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visualize import plot_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_df.columns[180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pred_df.where(pred_df['argmax'] == 0).dropna()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[[1, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_5(df, catdictpair):\n",
    "    CATNUM = df.shape[1] - 3 # files, maxval, argmax\n",
    "    for i in range(len(df)):\n",
    "        trans = df.iloc[i, 0:CATNUM].T.astype(float)\n",
    "        top5 = trans.nlargest(5)\n",
    "        respairs = [\"{0}:{1:.3f}\".format(get_key_from_value(catdictpair, idx), top5[idx]) for idx in top5.index]\n",
    "        print(\":\".join((\",\".join(respairs), df['files'].values[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_df_by_category(df, catdictpair, cattarget):\n",
    "    '''\n",
    "    input : prediction result df, category dictionary, index of class which you want to show, num of displaying images\n",
    "    output : plot of images (correct - prediction pairs)\n",
    "    '''\n",
    "    cat_name = get_key_from_value(catdictpair,cattarget)    \n",
    "    \n",
    "    catdf = df.where( \n",
    "            df['argmax'] == cattarget\n",
    "        ).dropna()\n",
    "    \n",
    "    \n",
    "    print(\"category: {}\".format(cat_name))\n",
    "    print_top_5(catdf, catdictpair)\n",
    "    plot_image_list(catdf['files'].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def checkimg(fpath):\n",
    "    display(Image(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show_df_by_category(pred_df, cat_dict_pair, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_DIST = './result_classified_07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "filtered_df = pred_df.where( \n",
    "            pred_df['maxval'] >= threshold\n",
    "        ).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_catidx_from_value(catdic, idx):\n",
    "    '''\n",
    "    input : category dictonary and index\n",
    "    output : key (category int value) of corresponding index\n",
    "    '''\n",
    "    idx_to_idxname_dict = catdic\n",
    "    key = list(idx_to_idxname_dict.keys())[\n",
    "        list( idx_to_idxname_dict.values() ).index(idx)\n",
    "    ]\n",
    "    return int(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, row in filtered_df.iterrows():\n",
    "    cat = row['argmax']\n",
    "    catname = get_key_from_value(cat_dict_pair, cat)\n",
    "    cat_path = os.path.join(RESULT_DIST, catname)\n",
    "    if not os.path.isdir(cat_path.encode('utf_8')):\n",
    "        os.makedirs(cat_path.encode('utf_8'))\n",
    "    orgpath = row['files']\n",
    "    shutil.copyfile(orgpath, os.path.join(cat_path, os.path.basename(orgpath)).encode('utf_8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunked_paths = CHECK_DATASET.chunked(DATA_PATHS, 3000)\n",
    "\n",
    "PREDICTIONS_SINGLE = []\n",
    "file_paths = []\n",
    "\n",
    "for chunk in chunked_paths:\n",
    "    check_data_chunk, file_path_chunk = CHECK_DATASET.preprocess_data(chunk,CATEGORY_DICT)\n",
    "    file_paths.extend(file_path_chunk)\n",
    "    \n",
    "    prediction = MODEL.predict_oneclass(check_data_chunk, batch_size=32)\n",
    "    PREDICTIONS_SINGLE.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULT_SINGLE = pd.DataFrame({\n",
    "    'predictions' : PREDICTIONS_SINGLE,\n",
    "    'filepaths' : file_paths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in filtered_df.iterrows():\n",
    "    cat = row['argmax']\n",
    "    catname = get_key_from_value(cat_dict_pair, cat)\n",
    "    catint = get_catidx_from_value(CATEGORY_DICT, cat)\n",
    "    cat_path = os.path.join(RESULT_DIST, str(catint))\n",
    "    if not os.path.isdir(cat_path):\n",
    "        os.makedirs(cat_path)\n",
    "        with open(os.path.join(cat_path, 'category_name.txt'), 'w') as f:\n",
    "            f.write(catname.encode('utf_8'))\n",
    "    orgpath = row['files']\n",
    "    shutil.copyfile(orgpath, os.path.join(cat_path, os.path.basename(orgpath)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
