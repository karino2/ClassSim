{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import sys\n",
    "from processor import preprocess\n",
    "\n",
    "import akagi\n",
    "print(\"akagi version:\", akagi.__version__)\n",
    "from akagi.data_sources import RedshiftDataSource, S3DataSource\n",
    "from akagi.iterator import FileFormat\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For restricted user data retrieval (from misc-internal bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('awskeys.txt', 'r') as outfile:\n",
    "    dic = json.load(outfile)\n",
    "AWS_KEY_ID = dic[\"AWS_KEY_ID\"]\n",
    "AWS_SECRET_KEY = dic[\"AWS_SECRET_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    assert (AWS_KEY_ID is not None) and (AWS_SECRET_KEY is not None), \"SET your keys.\"\n",
    "    os.mkdir(DATA_DIR) \n",
    "\n",
    "    REGION_NAME = \"ap-northeast-1\"\n",
    "    BUCKET_NAME = \"\"\n",
    "\n",
    "    DEFAULT_OUTPUT = \"text\"\n",
    "    DIST_DATA_DIR = os.path.normpath(DATA_DIR)\n",
    "    \n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = AWS_KEY_ID\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_KEY\n",
    "    os.environ['AWS_DEFAULT_REGION'] = REGION_NAME\n",
    "    os.environ['AWS_DEFAULT_OUTPUT'] = DEFAULT_OUTPUT\n",
    "\n",
    "    print(\"sync\")\n",
    "    !aws s3 sync {BUCKET_NAME} {DIST_DATA_DIR}\n",
    "    print(\"sync done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make download path consistent with akagi (we should have do that beforehand, but put code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data retreival code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DATA_DIR = \"\"\n",
    " \n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR) \n",
    "\n",
    "    with S3DataSource.for_prefix(\n",
    "        'research.ap-northeast-1',\n",
    "        '',\n",
    "        FileFormat.BINARY\n",
    "    ) as ds:\n",
    "        ds.save(DATA_DIR)\n",
    "    \n",
    "    with S3DataSource.for_prefix(\n",
    "        'research.ap-northeast-1',\n",
    "        '',\n",
    "        FileFormat.BINARY\n",
    "    ) as ds:\n",
    "        ds.save(DATA_DIR)\n",
    "    \n",
    "    with S3DataSource.for_prefix(\n",
    "        'research.ap-northeast-1',\n",
    "        '',\n",
    "        FileFormat.BINARY\n",
    "    ) as ds:\n",
    "        ds.save(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image resize size\n",
    "SIZE = 224\n",
    "\n",
    "#Data dirs {train, validation}\n",
    "TRAIN_DATA_DIR = os.path.normpath(os.path.join(DATA_DIR, \"\"))\n",
    "VALID_DATA_DIR = os.path.normpath(os.path.join(DATA_DIR, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATAGEN = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        channel_shift_range=0.2,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(\n",
    "        directory=TRAIN_DATA_DIR,\n",
    "        target_size=(SIZE, SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        seed=1729\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALID_DATAGEN = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_GENERATOR = VALID_DATAGEN.flow_from_directory(\n",
    "        directory=VALID_DATA_DIR,\n",
    "        target_size=(SIZE, SIZE),\n",
    "        class_mode='sparse',\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        seed=1729\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = \"imagenet\"\n",
    "TRAINED_MODEL_NAME = \"\"\n",
    "MODEL_SAVE_PATH = os.path.join(\"./trained_model/inceptionv3/\", TRAINED_MODEL_NAME)\n",
    "\n",
    "# BASE_MODEL_DIR = \"../../trained_model/inceptionv3/\"\n",
    "# TRAINED_MODEL_NAME = \"\"\n",
    "# BASE_MODEL_NAME = os.path.normpath(\"{}/{}\".format(BASE_MODEL_DIR, TRAINED_MODEL_NAME))\n",
    "# MODEL_SAVE_PATH = os.path.join(\"./trained_model/inceptionv3/\", TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "basemodel_layer_num = 311 #corresponding to len(base_model.layers)\n",
    "\n",
    "def complile_model(base_model_name, only_top_layer=False):\n",
    "    '''\n",
    "    input : base_model_name - 'imagenet' or model_prefix of your trained model\n",
    "    outpu : compiled model\n",
    "    '''\n",
    "    if base_model_name == 'imagenet':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        predictions = Dense(TRAIN_GENERATOR.num_class, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "    else:\n",
    "        with open(\"{0}.json\".format(base_model_name), 'r') as f:\n",
    "            model_json = json.dumps(json.load(f)) # Need to convert json to str\n",
    "            model = model_from_json(model_json)\n",
    "        with open(\"{0}-labels.json\".format(base_model_name), 'r') as f:\n",
    "            category_dict = json.load(f)\n",
    "            \n",
    "        model.load_weights(\"{0}.h5\".format(base_model_name))\n",
    "        model = Model(inputs=model.input, outputs=model.output)\n",
    "    \n",
    "    #Set layers be trainable\n",
    "    if only_top_layer:\n",
    "        for layer in model.layers[:basemodel_layer_num]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[basemodel_layer_num:]:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    #Model compile\n",
    "    optimizer = optimizers.Adam(lr=0.0001, decay=0.01)\n",
    "    #optimizer = optimizers.Adagrad(lr=0.0025, epsilon=1e-08, decay=0.01)\n",
    "    #optimizer = optimizers.SGD(lr=0.001, momentum=0.001, decay=0.001, nesterov=True)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "FILEPATH = MODEL_SAVE_PATH + \"-{epoch:02d}-{val_acc:.3f}.h5\"\n",
    "\n",
    "CHECKPOINT = ModelCheckpoint(\n",
    "    FILEPATH\n",
    "    , monitor='val_acc'\n",
    "    , verbose=1\n",
    "    , save_best_only=False\n",
    "    , mode='max'\n",
    ")\n",
    "\n",
    "EARLYSTOPPING = EarlyStopping(\n",
    "    monitor='val_loss'\n",
    "    , patience=5\n",
    "    , verbose=1\n",
    "    , mode='min'\n",
    ")\n",
    "\n",
    "CALLBACKS_LIST = [CHECKPOINT]\n",
    "#CALLBACKS_LIST = [CHECKPOINT, EARLYSTOPPING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    '''\n",
    "    input : keras model\n",
    "    output : trained model & save it\n",
    "    '''\n",
    "    with open(\"{0}.json\".format(MODEL_SAVE_PATH), 'w') as f:\n",
    "        json.dump(json.loads(model.to_json()), f) # model.to_json() is a STRING of json\n",
    "    with open(\"{0}-labels.json\".format(MODEL_SAVE_PATH), 'w') as f:\n",
    "        json.dump(TRAIN_GENERATOR.class_indices, f)\n",
    "\n",
    "    model.fit_generator(\n",
    "        generator=TRAIN_GENERATOR\n",
    "        #, steps_per_epoch= TRAIN_GENERATOR.n\n",
    "        , steps_per_epoch= 100\n",
    "        , epochs=5\n",
    "        , verbose=1\n",
    "        , validation_data=VALID_GENERATOR\n",
    "        #, validation_steps=VALID_GENERATOR.n\n",
    "        , validation_steps=10\n",
    "        , callbacks=CALLBACKS_LIST\n",
    "    )\n",
    "    \n",
    "    model.save_weights('{0}.h5'.format(MODEL_SAVE_PATH))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL = complile_model(BASE_MODEL_NAME, only_top_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = train_model(MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
