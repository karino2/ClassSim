{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking whether model is property trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_PATH=\"trained_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.modelutils import dir2filedict_sorted, split_fdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load category information and all of image paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdict = dir2filedict_sorted(\"data_fgvc/train\")\n",
    "valdict = dir2filedict_sorted(\"data_fgvc/valid\")\n",
    "categories = [str(i) for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_fgvc/valid/0/0062781.jpg',\n",
       " 'data_fgvc/valid/0/0113201.jpg',\n",
       " 'data_fgvc/valid/0/0450014.jpg',\n",
       " 'data_fgvc/valid/0/0602177.jpg',\n",
       " 'data_fgvc/valid/0/0716386.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdict['0'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is expected outputs.   \n",
    "All the outputs in {*train.ipynb*, *classifier_similarity.ipynb*, *train_multiclass_classifier.ipynb*, *train_second.ipynb*} must be the same. \n",
    "\n",
    "['data_fgvc/valid/0/0062781.jpg',  \n",
    " 'data_fgvc/valid/0/0198101.jpg',  \n",
    " 'data_fgvc/valid/0/0536721.jpg',  \n",
    " 'data_fgvc/valid/0/0602177.jpg',  \n",
    " 'data_fgvc/valid/0/0817494.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is validation set.\n",
    "fdict = valdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $ClassSim$ using OVR classifiers\n",
    "\n",
    "Now compute our proposed similarities using trained OVR classifiers in *train.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import load_best_model_if_exist\n",
    "import os\n",
    "from models.processor import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0, 7, 25\n",
    "model_0 = load_best_model_if_exist(\"trained_model/modelfgcv_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = valdict['0']+valdict['7']+valdict['25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 7, 7, 7, 7]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(valdict[str(cat)]) for cat in range(0, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ds.files_to_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_0.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.92395899e-02,   2.59536813e-04,   5.92470281e-02,\n",
       "         3.28918062e-02,   1.39725283e-01,   5.34679629e-02,\n",
       "         1.82478607e-01,   1.58299913e-03,   2.88571522e-04,\n",
       "         1.88934747e-02,   4.61065769e-03,   1.49370171e-03,\n",
       "         6.01889798e-04,   4.31226520e-03,   3.46300541e-03,\n",
       "         1.46281039e-02,   1.24871347e-03,   5.20068670e-06,\n",
       "         8.64843838e-04,   9.01830941e-03,   6.41005952e-03], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = load_best_model_if_exist(\"trained_model/modelfgcv_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res7 = model_7.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79513288,  0.94284797,  0.52979416,  0.004935  ,  0.977696  ,\n",
       "        0.91841048,  0.95773572,  0.99248064,  0.97794801,  0.98844063,\n",
       "        0.99942929,  0.99754745,  0.9922483 ,  0.98539889,  0.71566725,\n",
       "        0.95446295,  0.98618662,  0.99400312,  0.98530722,  0.97016662,\n",
       "        0.97104281], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res7[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_25 = load_best_model_if_exist(\"trained_model/modelfgcv_25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res25 = model_25.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96423489,  0.95057374,  0.98104322,  0.98065484,  0.98563081,\n",
       "        0.96160883,  0.92907143,  0.99927717,  0.9276554 ,  0.95660198,\n",
       "        0.90638232,  0.95786446,  0.93434954,  0.94946223,  0.99442321,\n",
       "        0.94495463,  0.89362717,  0.98713171,  0.88144904,  0.97600114,\n",
       "        0.97630274], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res25[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
