{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance test of $two \\ level \\ model$.\n",
    "\n",
    "$two \\ level \\ model$ is composed of first set of OVR classifiers $f_{c, other}$ and secnd set of OVR classifiers $f^{(2)}_{c, other}$ .  \n",
    "We test the model using a classification task, which is compared to the results of a baseline model that uses only $f_{c, other}$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix typo of fgcv->fgvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.iglob(\"trained_model/modelfgcv*\"):\n",
    "    os.rename(f, \"trained_model/modelfgvc\" + f[len('trained_model/modelfgcv'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.modelutils import dir2filedict_sorted\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load category and file path information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict = dir2filedict_sorted(\"data_fgvc/test\")\n",
    "categories = [str(i) for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create (category, path) information of test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for debug\n",
    "# org_testdict = testdict\n",
    "# categories = [str(i) for i in range(0, 3)]\n",
    "# testdict = {key: org_testdict[key] for key in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtup = [(key, file) for key in categories for file in testdict[key] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testtup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'data_fgvc/test/0/0062765.jpg'),\n",
       " ('0', 'data_fgvc/test/0/0064932.jpg'),\n",
       " ('0', 'data_fgvc/test/0/0197342.jpg'),\n",
       " ('0', 'data_fgvc/test/0/0447936.jpg'),\n",
       " ('0', 'data_fgvc/test/0/0536515.jpg')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtup[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the list into a Pandas DataFrame for simple treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame({\"category\": [tup[0] for tup in testtup], \"files\": [tup[1] for tup in testtup]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf_shuffled=testdf.sample(frac=1, random_state=123).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>data_fgvc/test/13/2233262.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>data_fgvc/test/72/1372357.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>data_fgvc/test/53/0773531.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>data_fgvc/test/39/1340322.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>data_fgvc/test/13/1313993.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                          files\n",
       "0       13  data_fgvc/test/13/2233262.jpg\n",
       "1       72  data_fgvc/test/72/1372357.jpg\n",
       "2       53  data_fgvc/test/53/0773531.jpg\n",
       "3       39  data_fgvc/test/39/1340322.jpg\n",
       "4       13  data_fgvc/test/13/1313993.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf_shuffled.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First level and second level must be the same order. (The same as below must be enough).\n",
    "\n",
    "    category\tfiles\n",
    "0\t13\tdata_fgvc/test/13/2233262.jpg\n",
    "1\t72\tdata_fgvc/test/72/1372357.jpg\n",
    "2\t53\tdata_fgvc/test/53/0773531.jpg\n",
    "3\t39\tdata_fgvc/test/39/1340322.jpg\n",
    "4\t13\tdata_fgvc/test/13/1313993.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes for $two \\ level \\ model$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelutils import load_best_model_if_exist\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBinder:\n",
    "    def __init__(self, base_model_name, basedir, cats):\n",
    "        self.base_model_name = base_model_name\n",
    "        self.basedir = basedir\n",
    "        self._models = {}\n",
    "        self.verbose = True\n",
    "        self._categories = cats\n",
    "        self._OTHER_LABEL = \"other\"\n",
    "\n",
    "    @classmethod\n",
    "    def dup_from(cls, binder):\n",
    "        return ModelBinder(binder.base_model_name, binder.basedir, binder._categories)\n",
    "\n",
    "    def model_path(self, target_key):\n",
    "        return os.path.join(self.basedir, \"{}_{}\".format(self.base_model_name, target_key))\n",
    "\n",
    "    def get_or_load_model(self, target_key):\n",
    "        if target_key in self._models:\n",
    "            return self._models[target_key]\n",
    "        self.notify(\"load {}\".format(target_key))\n",
    "        self._models[target_key] = load_best_model_if_exist(self.model_path(target_key))\n",
    "        return self._models[target_key]\n",
    "\n",
    "    def notify(self, msg):\n",
    "        if self.verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def load_all_models(self, keys):\n",
    "        list(map(self.get_or_load_model, keys))\n",
    "        \n",
    "    def predict_one_with_log(self, key, arrs):\n",
    "        self.notify(\"predict {}.\".format(key))\n",
    "        return self._models[key].predict(arrs)\n",
    "        \n",
    "    def predict_arrs(self, arrs):\n",
    "        models = self._models\n",
    "        preddict = {key: self.predict_one_with_log(key, arrs)[:, 1] for key in models.keys()}\n",
    "        return pd.DataFrame(preddict)\n",
    "    \n",
    "    def _row2class(self, rowdf, threshold):\n",
    "        for cat in self._categories:\n",
    "            if rowdf[cat] >= threshold:\n",
    "                return cat\n",
    "        return self._OTHER_LABEL\n",
    "\n",
    "    def df2classes(self, df, threshold = 0.5):\n",
    "        res = []\n",
    "        for i in range(len(df)):\n",
    "            rowdf = df.iloc[i, :]\n",
    "            res.append(self._row2class(rowdf, threshold))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLevelModel:\n",
    "    def __init__(self, categories, h1binder, otherlabel=\"OTHER\"):\n",
    "        self._categories = categories\n",
    "        self._h1binder = h1binder\n",
    "        self._OTHERCLASS = -1\n",
    "        self._OTHERLABEL = otherlabel\n",
    "        # initial trial.\n",
    "        self._FIRST_THRESHOLD = 0.8\n",
    "        self._SECOND_THRESHOLD = 0.5\n",
    "        self.verbose = True\n",
    "        \n",
    "    def notify(self, msg):\n",
    "        if self.verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def load_all(self):\n",
    "        catkeys = self._categories\n",
    "        self._h1binder.load_all_models([\"sec_\" + cat for cat in catkeys])\n",
    "\n",
    "    def predict_arrs(self, arrs, firstdf):\n",
    "        df = self._predict_arrs(arrs, firstdf)\n",
    "        self._df = df\n",
    "        return self._h1binder.df2classes(df, self._SECOND_THRESHOLD)\n",
    "\n",
    "    def _predict_arrs(self, arrs, firstdf):\n",
    "        # firstdf = pd.DataFrame(self._h2binder.predict_arrs(arrs))\n",
    "\n",
    "        resultdf = pd.DataFrame(np.zeros(firstdf.shape))\n",
    "        resultdf.columns = firstdf.columns\n",
    "\n",
    "        for targetkey in self._categories:\n",
    "\n",
    "            df = self._predict_second(targetkey, arrs, firstdf)\n",
    "            if df is not None:\n",
    "                resultdf.loc[df['orgindex'], targetkey] = df[targetkey].values\n",
    "\n",
    "        return resultdf\n",
    "\n",
    "    def _predict_second(self, targetcat, arrs, firstdf):\n",
    "        filtered = firstdf[firstdf[targetcat] > self._FIRST_THRESHOLD]\n",
    "\n",
    "        if len(filtered) == 0:\n",
    "            return None\n",
    "\n",
    "        farrs = arrs[filtered.index, :]\n",
    "        model = self._h1binder.get_or_load_model('sec_' + targetcat)\n",
    "\n",
    "        # no second level classifier, all score is already enough.\n",
    "        if model == None:\n",
    "            return pd.DataFrame({targetcat: np.ones(len(filtered.index)), 'orgindex': filtered.index})\n",
    "\n",
    "        self.notify(\"predict {}\".format('sec_' + targetcat))\n",
    "        res = model.predict(farrs)\n",
    "        scores = res[:, 1]\n",
    "\n",
    "        return pd.DataFrame({targetcat: scores, 'orgindex': filtered.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.processor import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct first level prediction (h2 prediction) and store result.\n",
    "\n",
    "Also evaluate baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "binder = ModelBinder( \"modelfgvc\", \"trained_model\", categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0\n",
      "load 1\n",
      "load 2\n"
     ]
    }
   ],
   "source": [
    "binder.load_all_models(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate baseline model\n",
    "\n",
    "Classifiers are trained in *train.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for debug\n",
    "# org_testdf_shuffled = testdf_shuffled\n",
    "# testdf_shuffled = org_testdf_shuffled[0:5]\n",
    "# testdf_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for debug\n",
    "# modelsbackup = binder._models\n",
    "# binder._models = {key: modelsbackup[key] for key in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predit 0.\n",
      "predit 1.\n",
      "predit 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.55s/it]\n"
     ]
    }
   ],
   "source": [
    "all_labels = pd.Series(dtype=object)\n",
    "all_results = []\n",
    "all_result_dfs = []\n",
    "\n",
    "for chunk in tqdm.tqdm(ds.chunked(testdf_shuffled, 500)):\n",
    "    x = ds.files_to_dataset(chunk['files'])\n",
    "    label = chunk['category']\n",
    "    resdf = binder.predict_arrs(x)\n",
    "    # to compare two level model, we use threshold 0.8 for initial trial.\n",
    "    resclasses = binder.df2classes(resdf, threshold =0.8)\n",
    "    \n",
    "    all_labels = all_labels.append(label,  ignore_index=True)\n",
    "    all_results.extend(resclasses)\n",
    "    all_result_dfs.append(resdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 5\n",
      "Accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test images: {}\\nAccuracy: {}\".format(len(all_labels), float(sum(all_labels == all_results))/len(all_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results as picke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"labels\": all_labels, \"prediction\": all_results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(\"results/baseline_model_prediction_fgvc.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2df = pd.concat(all_result_dfs)\n",
    "h2df.index = testdf_shuffled.index\n",
    "h2df['files'] = testdf_shuffled[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2df.to_pickle(\"results/baseline_h2_df_fgvc.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate $two \\ level \\ model$\n",
    "\n",
    "Classifiers are trained in *train_second.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2df = pd.read_pickle(\"results/baseline_h2_df_fgvc.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix of corrupted files column in h2df due to first version of bug (not necessary if you don't use old h2df dat)\n",
    "h2df.index = testdf_shuffled.index\n",
    "h2df['files'] = testdf_shuffled[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_binder = ModelBinder( \"modelfgvc\", \"trained_model\", categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_level_model = TwoLevelModel(categories, sec_binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load sec_0\n",
      "load sec_1\n",
      "load sec_2\n",
      "load sec_3\n",
      "load sec_4\n"
     ]
    }
   ],
   "source": [
    "two_level_model.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2_subset(h2df, files):\n",
    "    h2sub = h2df[h2df['files'].isin(files)][list(set(h2df.columns) - {\"files\"})]\n",
    "    h2sub.index = range(0, h2sub.shape[0])\n",
    "    return h2sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.18s/it]\n"
     ]
    }
   ],
   "source": [
    "all_labels2 = pd.Series(dtype=object)\n",
    "all_results2 = []\n",
    "\n",
    "for chunk in tqdm.tqdm(ds.chunked(testdf_shuffled, 500)):\n",
    "    x = ds.files_to_dataset(chunk['files'])\n",
    "    label = chunk['category']\n",
    "    firstdf = h2_subset(h2df, chunk['files'])\n",
    "    resclasses = two_level_model.predict_arrs(x, firstdf)\n",
    "    \n",
    "    all_labels2 = all_labels2.append(label,  ignore_index=True)\n",
    "    all_results2.extend(resclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 5\n",
      "Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test images: {}\\nAccuracy: {}\".format(len(all_labels2), float(sum(all_labels2 == all_results2))/len(all_labels2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results as pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df2 = pd.DataFrame({\"labels\": all_labels2, \"prediction\": all_results2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df2.to_pickle(\"results/twolevelmodel_prediction_fgvc.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Class Accuracy\n",
    "\n",
    "https://arxiv.org/pdf/1306.5151.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twolevelmodel_prediction.dat\n",
    "results_df1 = pd.read_pickle(\"results/baseline_model_prediction_fgvc.dat\")\n",
    "results_df2 = pd.read_pickle(\"results/twolevelmodel_prediction_fgvc.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [str(i) for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tp(df, cat):\n",
    "    trs = (df[\"labels\"] == cat)\n",
    "    prds = (df[\"prediction\"] == cat)\n",
    "    return sum(trs & prds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP2 = {cat: calc_tp(results_df2, cat) for cat in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP1 = {cat: calc_tp(results_df1, cat) for cat in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(TP1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(TP2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.48979591836735"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sum(TP2.values())/sum(TP1.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Cpp(df, cat):\n",
    "    return calc_tp(df, cat)/sum(df[\"labels\"]==cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna2_list = [calc_Cpp(results_df2, cat) for cat in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10616755793226382"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cna2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna1_list = [calc_Cpp(results_df1, cat) for cat in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.073556149732620313"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cna1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
